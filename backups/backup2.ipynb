{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LineupLab**: NBA Matchup Prediction using Transformer Networks\n",
    "\n",
    "## Project Overview\n",
    "This project is part of the final requirement for the **Introduction to Deep Learning** course. The objective is to develop a machine learning model that predicts NBA matchup outcomes based on player lineups and team configurations. \n",
    "\n",
    "By leveraging the BallDontLie API, we will retrieve, clean, and process NBA data to create a dataset suitable for training and testing. A transformer-based deep learning model will be implemented using PyTorch to analyze player lineups and generate predictions.\n",
    "\n",
    "## Goals\n",
    "1. **Data Exploration**: Analyze and preprocess NBA data to ensure compatibility with the model.\n",
    "2. **Model Creation**: Build a transformer network to learn relationships between players in a lineup and predict game outcomes.\n",
    "3. **Hyperparameter Tuning**: Experiment with learning rate, optimizer, number of epochs, and other hyperparameters to optimize performance.\n",
    "4. **Evaluation and Analysis**: Evaluate model performance using metrics such as accuracy, loss, and F1-score. Provide insights into the model's strengths, limitations, and potential improvements.\n",
    "\n",
    "## Key Features\n",
    "- **Transformer Networks**: Leveraging multi-head attention to capture player and team relationships.\n",
    "- **Comprehensive Dataset**: Utilizing player stats, game results, and team information from the BallDontLie API.\n",
    "- **Visualization and Analysis**: Incorporating visual representations of data distributions, training progress, and performance metrics.\n",
    "\n",
    "This notebook will serve as the main documentation for the project, including all steps from data retrieval to model evaluation.\n",
    "\n",
    "Created with the aid of ChatGPT 4o - Using AI to build AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import requests  # For API requests\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import torch  # For deep learning model implementation\n",
    "import torch.nn as nn  # For neural network components\n",
    "import torch.optim as optim  # For optimization algorithms\n",
    "from torch.utils.data import Dataset, DataLoader  # For data handling in PyTorch\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "from nba_api.stats.endpoints import leaguedashlineups\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Ensure plots are displayed inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Display confirmation message\n",
    "print(\"Libraries successfully loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **I. Data Exploration and Preparation**\n",
    "\n",
    "### Overview\n",
    "In this section, we will collect, prepare, and process NBA data using the **BallDontLie API** to build a dataset for training a transformer-based deep learning model.\n",
    "\n",
    "### Goals and Actions\n",
    "1. **Data Collection**:\n",
    "   - Retrieve detailed NBA game data (2003–2023) using game IDs.\n",
    "   - Collect individual player statistics (e.g., minutes played, offensive and defensive ratings, usage percentages) for each game.\n",
    "   - Extract team information (e.g., home and away team IDs, scores) and player metadata (e.g., names, positions).\n",
    "\n",
    "2. **Data Cleaning**:\n",
    "   - Normalize data formats, particularly for time strings (e.g., parsing minutes played).\n",
    "   - Handle missing or incomplete data by assigning default or null values where necessary.\n",
    "   - Rename and standardize column names (e.g., `id` → `game_id`) for consistency.\n",
    "\n",
    "3. **Parallelized Processing**:\n",
    "   - Implement a **threaded processing solution** to speed up API calls and data extraction.\n",
    "   - Use incremental saving to ensure progress is retained during long data processing tasks.\n",
    "\n",
    "4. **Dataset Preparation**:\n",
    "   - Combine game-level and player-level statistics into a single dataset.\n",
    "   - Structure the data for model input, including creating columns for the top 12 players (home and away) with their associated metrics.\n",
    "   - Include player positions directly from the API to enhance the feature set for modeling.\n",
    "\n",
    "5. **Static Tensor Creation**:\n",
    "   - Generate and save **static tensors** for each game, containing normalized, game-independent features for both teams.\n",
    "   - Normalize features (e.g., player stats, height, and weight) using `MinMaxScaler` for consistency.\n",
    "   - Organize tensors in season-specific directories (`static_game_tensors`) for efficient retrieval during training.\n",
    "   - Ensure static tensors are padded to maintain consistent dimensions for the transformer network.\n",
    "\n",
    "### Summary\n",
    "This section provides the foundation for the predictive model by ensuring the dataset is comprehensive, clean, and ready for efficient use in a transformer-based deep learning framework. The data is now structured and stored in a format that enables seamless integration with dynamic encodings during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Game Data for NBA Seasons 2003–2023\n",
    "# -----------------------------------------------------------\n",
    "# This script retrieves game data for NBA seasons between 2003 and 2023 \n",
    "# using the BallDon'tLie API. The data includes game IDs, dates, seasons, \n",
    "# scores, team names, and team IDs for home and away teams. \n",
    "# The data is retrieved in a paginated manner and stored in a CSV file \n",
    "# for future use in analysis or model training.\n",
    "\n",
    "# Key Steps:\n",
    "# 1. Define the API base URL and authorization key for secure access.\n",
    "# 2. Set the range of seasons (2003–2023) for which data will be fetched.\n",
    "# 3. Define a function (`fetch_games_for_season`) that:\n",
    "#    - Iterates through the pages of results for a given season using cursors.\n",
    "#    - Handles potential API rate limits with throttling.\n",
    "#    - Handles errors with retry logic.\n",
    "#    - Collects game data in a structured format.\n",
    "# 4. Iterate over each season and call the function to retrieve all games.\n",
    "# 5. Convert the collected raw data into a structured Pandas DataFrame, \n",
    "#    with relevant columns such as game date, season, scores, team names, \n",
    "#    and team IDs.\n",
    "# 6. Save the DataFrame to a CSV file named `games_2003_2023.csv`.\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Note:\n",
    "# - Throttling (`time.sleep`) is used to avoid hitting API rate limits.\n",
    "# - A retry mechanism waits 60 seconds in case of a non-200 response.\n",
    "# - Paginated API responses are managed using a `cursor` for fetching \n",
    "#   additional pages of data until no more data is available.\n",
    "# - The collected data is structured in a list of dictionaries and \n",
    "#   transformed into a Pandas DataFrame for easier manipulation.\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Base URL and API Key\n",
    "BASE_URL = \"https://api.balldontlie.io/v1/games\"\n",
    "API_KEY = \"\"\n",
    "\n",
    "# Headers for the API request\n",
    "HEADERS = {\n",
    "    \"Authorization\": API_KEY\n",
    "}\n",
    "\n",
    "# Define the seasons to retrieve (2003 to 2023)\n",
    "START_YEAR = 2003\n",
    "END_YEAR = 2023\n",
    "\n",
    "# List to store game data\n",
    "all_games = []\n",
    "\n",
    "# Function to fetch games for a specific season\n",
    "def fetch_games_for_season(season):\n",
    "    cursor = None  # Start without a cursor\n",
    "    while True:\n",
    "        print(f\"Fetching season {season}, cursor: {cursor}\")\n",
    "        \n",
    "        # Construct the API URL with cursor for pagination\n",
    "        url = f\"{BASE_URL}?seasons[]={season}&per_page=100\"\n",
    "        if cursor:\n",
    "            url += f\"&cursor={cursor}\"\n",
    "        \n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data: {response.status_code}. Retrying in 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        data = response.json()\n",
    "        \n",
    "        # Ensure the response contains new data\n",
    "        if not data['data']:\n",
    "            print(f\"No more data found for season {season}, exiting loop.\")\n",
    "            break  # Exit loop if no more games are found\n",
    "\n",
    "        # Add new games to the list\n",
    "        all_games.extend(data['data'])\n",
    "        print(f\"Fetched {len(data['data'])} games. Total games collected: {len(all_games)}\")\n",
    "        \n",
    "        # Update the cursor for the next page\n",
    "        cursor = data.get('meta', {}).get('next_cursor', None)\n",
    "        if not cursor:  # No more pages\n",
    "            print(f\"All pages fetched for season {season}.\")\n",
    "            break\n",
    "        \n",
    "        # Throttle requests to avoid hitting rate limits\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Fetch data for each season\n",
    "for season in range(START_YEAR, END_YEAR + 1):\n",
    "    fetch_games_for_season(season)\n",
    "\n",
    "# Process the collected data into a DataFrame\n",
    "print(\"Processing data into DataFrame...\")\n",
    "games_data = [\n",
    "    {\n",
    "        \"id\": game[\"id\"],\n",
    "        \"date\": game[\"date\"],\n",
    "        \"season\": game[\"season\"],\n",
    "        \"status\": game[\"status\"],\n",
    "        \"home_team_score\": game[\"home_team_score\"],\n",
    "        \"visitor_team_score\": game[\"visitor_team_score\"],\n",
    "        \"home_team_name\": game[\"home_team\"][\"full_name\"],\n",
    "        \"home_team_id\": game[\"home_team\"][\"id\"],\n",
    "        \"visitor_team_name\": game[\"visitor_team\"][\"full_name\"],\n",
    "        \"visitor_team_id\": game[\"visitor_team\"][\"id\"]\n",
    "    }\n",
    "    for game in all_games\n",
    "]\n",
    "\n",
    "games_df = pd.DataFrame(games_data)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "output_file = \"games_2003_2023.csv\"\n",
    "games_df.to_csv(output_file, index=False)\n",
    "print(f\"Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Success!** We have successfully gathered the scores for every game from 2003-2023\n",
    "\n",
    "#### Now we will enrich this data-frame with the top 12 most used players for each team including their Player-ID's, Position, Minutes, Offensive Rating, Defensive Rating, and Usage Pctg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of how we are going to expand data with information from stats and advanced_stats - we will do this on a loop for every game we have gathered\n",
    "game_id = 15486  # Example game ID\n",
    "\n",
    "# Base URLs and API Key\n",
    "BASE_URL_STATS = \"https://api.balldontlie.io/v1/stats\"\n",
    "BASE_URL_ADVANCED = \"https://api.balldontlie.io/v1/stats/advanced\"\n",
    "API_KEY = \"\"\n",
    "HEADERS = {\"Authorization\": API_KEY}\n",
    "\n",
    "# Function to fetch stats\n",
    "def fetch_stats(url, game_id):\n",
    "    response = requests.get(f\"{url}?game_ids[]={game_id}&per_page=100\", headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"data\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error fetching stats: {response.status_code}, {response.text}\")\n",
    "\n",
    "# Refined parse_minutes function\n",
    "def parse_minutes(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            if \":\" in value:  # Time string in \"MM:SS\" format\n",
    "                parts = value.split(\":\")\n",
    "                minutes = int(parts[0])\n",
    "                seconds = int(parts[1])\n",
    "                return minutes + seconds / 60  # Convert seconds to fractional minutes\n",
    "            elif value.isdigit():  # Whole number string like \"38\"\n",
    "                return float(value)  # Convert directly to float\n",
    "        return 0  # Default for invalid or missing values\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing minutes value '{value}': {e}\")\n",
    "        return 0\n",
    "\n",
    "# Fetch data\n",
    "base_stats = fetch_stats(BASE_URL_STATS, game_id)\n",
    "advanced_stats = fetch_stats(BASE_URL_ADVANCED, game_id)\n",
    "\n",
    "# Convert to DataFrames\n",
    "base_df = pd.DataFrame(base_stats)\n",
    "adv_df = pd.DataFrame(advanced_stats)\n",
    "\n",
    "# Parse minutes played\n",
    "base_df[\"minutes_played\"] = base_df[\"min\"].apply(parse_minutes)\n",
    "\n",
    "# Merge base and advanced stats on player ID\n",
    "base_df[\"player_id\"] = base_df[\"player\"].apply(lambda x: x[\"id\"])\n",
    "adv_df[\"player_id\"] = adv_df[\"player\"].apply(lambda x: x[\"id\"])\n",
    "adv_df[\"position\"] = adv_df[\"player\"].apply(lambda x: x.get(\"position\", None))  # Extract position\n",
    "merged_df = pd.merge(\n",
    "    base_df,\n",
    "    adv_df[[\"player_id\", \"offensive_rating\", \"defensive_rating\", \"usage_percentage\", \"position\"]],\n",
    "    on=\"player_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Add team and player full name\n",
    "merged_df[\"team_id\"] = merged_df[\"team\"].apply(lambda x: x[\"id\"])\n",
    "merged_df[\"team_name\"] = merged_df[\"team\"].apply(lambda x: x[\"full_name\"])\n",
    "merged_df[\"full_name\"] = merged_df[\"player\"].apply(lambda x: f\"{x['first_name']} {x['last_name']}\")\n",
    "\n",
    "# Split into home and away teams and take top 12 players by minutes played\n",
    "home_team_id = 14  # Los Angeles Lakers\n",
    "away_team_id = 7   # Dallas Mavericks\n",
    "home_players = merged_df[merged_df[\"team_id\"] == home_team_id].nlargest(12, \"minutes_played\")\n",
    "away_players = merged_df[merged_df[\"team_id\"] == away_team_id].nlargest(12, \"minutes_played\")\n",
    "\n",
    "# Print top 12 players for each team\n",
    "print(\"\\nTop 12 Home Players:\")\n",
    "print(home_players[[\"full_name\", \"team_name\", \"minutes_played\", \"position\", \"offensive_rating\", \"defensive_rating\", \"usage_percentage\"]])\n",
    "\n",
    "print(\"\\nTop 12 Away Players:\")\n",
    "print(away_players[[\"full_name\", \"team_name\", \"minutes_played\", \"position\", \"offensive_rating\", \"defensive_rating\", \"usage_percentage\"]])\n",
    "\n",
    "# Combine results into a single row for testing\n",
    "game_row = {\n",
    "    \"id\": game_id,\n",
    "    \"date\": \"2003-10-28\",\n",
    "    \"season\": 2003,\n",
    "    \"status\": \"Final\",\n",
    "    \"home_team_score\": 109,\n",
    "    \"visitor_team_score\": 93,\n",
    "    \"home_team_name\": \"Los Angeles Lakers\",\n",
    "    \"home_team_id\": home_team_id,\n",
    "    \"visitor_team_name\": \"Dallas Mavericks\",\n",
    "    \"visitor_team_id\": away_team_id,\n",
    "}\n",
    "\n",
    "for i in range(1, 13):\n",
    "    if i <= len(home_players):\n",
    "        game_row[f\"home_player_{i}_id\"] = home_players.iloc[i - 1][\"player_id\"]\n",
    "        game_row[f\"home_player_{i}_name\"] = home_players.iloc[i - 1][\"full_name\"]\n",
    "        game_row[f\"home_player_{i}_minutes\"] = home_players.iloc[i - 1][\"minutes_played\"]\n",
    "        game_row[f\"home_player_{i}_position\"] = home_players.iloc[i - 1][\"position\"]\n",
    "        game_row[f\"home_player_{i}_off_rating\"] = home_players.iloc[i - 1][\"offensive_rating\"]\n",
    "        game_row[f\"home_player_{i}_def_rating\"] = home_players.iloc[i - 1][\"defensive_rating\"]\n",
    "        game_row[f\"home_player_{i}_usage\"] = home_players.iloc[i - 1][\"usage_percentage\"]\n",
    "    else:\n",
    "        game_row[f\"home_player_{i}_id\"] = None\n",
    "        game_row[f\"home_player_{i}_name\"] = None\n",
    "        game_row[f\"home_player_{i}_minutes\"] = None\n",
    "        game_row[f\"home_player_{i}_position\"] = None\n",
    "        game_row[f\"home_player_{i}_off_rating\"] = None\n",
    "        game_row[f\"home_player_{i}_def_rating\"] = None\n",
    "        game_row[f\"home_player_{i}_usage\"] = None\n",
    "\n",
    "    if i <= len(away_players):\n",
    "        game_row[f\"away_player_{i}_id\"] = away_players.iloc[i - 1][\"player_id\"]\n",
    "        game_row[f\"away_player_{i}_name\"] = away_players.iloc[i - 1][\"full_name\"]\n",
    "        game_row[f\"away_player_{i}_minutes\"] = away_players.iloc[i - 1][\"minutes_played\"]\n",
    "        game_row[f\"away_player_{i}_position\"] = away_players.iloc[i - 1][\"position\"]\n",
    "        game_row[f\"away_player_{i}_off_rating\"] = away_players.iloc[i - 1][\"offensive_rating\"]\n",
    "        game_row[f\"away_player_{i}_def_rating\"] = away_players.iloc[i - 1][\"defensive_rating\"]\n",
    "        game_row[f\"away_player_{i}_usage\"] = away_players.iloc[i - 1][\"usage_percentage\"]\n",
    "    else:\n",
    "        game_row[f\"away_player_{i}_id\"] = None\n",
    "        game_row[f\"away_player_{i}_name\"] = None\n",
    "        game_row[f\"away_player_{i}_minutes\"] = None\n",
    "        game_row[f\"away_player_{i}_position\"] = None\n",
    "        game_row[f\"away_player_{i}_off_rating\"] = None\n",
    "        game_row[f\"away_player_{i}_def_rating\"] = None\n",
    "        game_row[f\"away_player_{i}_usage\"] = None\n",
    "\n",
    "# Create final DataFrame\n",
    "final_df = pd.DataFrame([game_row])\n",
    "\n",
    "# Save the data to a CSV file\n",
    "output_file = \"miniexp_games_2003_2023_top12_with_positions.csv\"\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing games DataFrame, and expand with our new categories ready to be filled in the next step\n",
    "games_df = pd.read_csv(\"games_2003_2023.csv\")\n",
    "\n",
    "# Define the player-specific columns for home and away teams, including position\n",
    "player_columns = []\n",
    "for i in range(1, 13):\n",
    "    player_columns.extend([\n",
    "        f\"home_player_{i}_id\", f\"home_player_{i}_name\", f\"home_player_{i}_position\",\n",
    "        f\"home_player_{i}_minutes\", f\"home_player_{i}_off_rating\",\n",
    "        f\"home_player_{i}_def_rating\", f\"home_player_{i}_usage\",\n",
    "    ])\n",
    "for i in range(1, 13):\n",
    "    player_columns.extend([\n",
    "        f\"away_player_{i}_id\", f\"away_player_{i}_name\", f\"away_player_{i}_position\",\n",
    "        f\"away_player_{i}_minutes\", f\"away_player_{i}_off_rating\",\n",
    "        f\"away_player_{i}_def_rating\", f\"away_player_{i}_usage\",\n",
    "    ])\n",
    "\n",
    "# Create an empty DataFrame for player columns\n",
    "empty_player_df = pd.DataFrame(columns=player_columns)\n",
    "\n",
    "# Initialize all values as None\n",
    "for col in empty_player_df.columns:\n",
    "    empty_player_df[col] = None\n",
    "\n",
    "# Append the empty player DataFrame to games_df\n",
    "games_df = pd.concat([games_df, empty_player_df], axis=1)\n",
    "\n",
    "# Rename the `id` column to `game_id`\n",
    "if 'id' in games_df.columns:\n",
    "    games_df.rename(columns={'id': 'game_id'}, inplace=True)\n",
    "    print(\"Column 'id' renamed to 'game_id'.\")\n",
    "else:\n",
    "    print(\"'id' column not found. Ensure the dataset is correct.\")\n",
    "\n",
    "# Save the updated dataset\n",
    "expanded_games_file_updated = \"expanded_games_2003_2023.csv\"\n",
    "games_df.to_csv(expanded_games_file_updated, index=False)\n",
    "print(f\"Updated dataset saved as {expanded_games_file_updated}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Great.** Now we are ready to load our player statistics from historic data into the expanded_games_2003_2023.csv file\n",
    "#### We are now going to be parsing JSON from BallDontLie's Basic and Advanced statistics for player data using game_id.\n",
    "#### This was taking quite a while (originally was going to take like 12+ hours - without error - to upload). So, I created a threaded implementation to speed things up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling out the expanded_games_2003_2023 file with the player-by-player data retrieved from BallDon'tLie's base and advanced player statistics API calls.\n",
    "# \n",
    "# This script is designed to enhance the existing game dataset (`expanded_games_2003_2023.csv`) \n",
    "# by appending detailed player-level statistics for each game. The data includes both basic \n",
    "# and advanced player statistics fetched from two API endpoints. \n",
    "# \n",
    "# Key Steps:\n",
    "# 1. **Load Dataset**:\n",
    "#    - Load the existing game data into a Pandas DataFrame. This file is assumed to already \n",
    "#      contain game-level details such as game ID, teams, and scores, along with placeholders \n",
    "#      for player-level statistics.\n",
    "#    - Check for the existence of the file to prevent errors.\n",
    "# \n",
    "# 2. **Identify Unprocessed Games**:\n",
    "#    - Determine which games are missing player-level data by checking for `NaN` values in the \n",
    "#      player-related columns (e.g., `home_player_1_id`).\n",
    "#    - Create a list of `game_id`s for games that need processing.\n",
    "# \n",
    "# 3. **Set Up Multithreading**:\n",
    "#    - Use Python's `ThreadPoolExecutor` to process games concurrently, improving efficiency \n",
    "#      for large datasets.\n",
    "#    - Implement a `lock` to ensure safe access to shared resources like the `games_df` DataFrame.\n",
    "#    - Define a `batch_size` to periodically save progress during processing.\n",
    "# \n",
    "# 4. **Fetch and Process Data for Each Game**:\n",
    "#    - Use the `fetch_stats` function to retrieve player statistics from the base and advanced \n",
    "#      API endpoints for a given game ID.\n",
    "#    - Parse the fetched data into DataFrames and calculate additional metrics, such as \n",
    "#      `minutes_played`, by transforming raw values.\n",
    "#    - Merge the base and advanced stats using `player_id` as the key and extract relevant \n",
    "#      player attributes like offensive/defensive ratings, usage percentage, and position.\n",
    "# \n",
    "# 5. **Organize Player Data**:\n",
    "#    - Separate players into home and away teams based on `team_id`.\n",
    "#    - Select the top 12 players per team based on minutes played to ensure relevance.\n",
    "#    - Populate a dictionary (`player_data`) with player statistics for each team, including \n",
    "#      placeholders for missing players (set to `None`).\n",
    "# \n",
    "# 6. **Update the Dataset**:\n",
    "#    - Use the `update_games_df` function to fill in the player-level columns for each game in \n",
    "#      the main DataFrame.\n",
    "#    - Save progress periodically using the `save_progress` function, ensuring no data is lost \n",
    "#      in case of an interruption.\n",
    "# \n",
    "# 7. **Final Save**:\n",
    "#    - Once all games are processed, save the completed dataset to a file.\n",
    "#    - Print a confirmation message to indicate the process is complete.\n",
    "# \n",
    "# Notes:\n",
    "# - The script includes error handling to skip games with missing or invalid data, logging \n",
    "#   messages to inform the user of any issues.\n",
    "# - Multithreading significantly reduces processing time for large datasets but requires careful \n",
    "#   management of shared resources to avoid data corruption.\n",
    "# - API responses are parsed and validated to ensure compatibility with the dataset structure.\n",
    "# \n",
    "# The final output is an updated CSV file (`expanded_games_2003_2023.csv`) containing both game-level \n",
    "# and player-level statistics, ready for advanced analysis or model training.\n",
    "\n",
    "expanded_games_file = \"expanded_games_2003_2023.csv\"\n",
    "if os.path.exists(expanded_games_file):\n",
    "    games_df = pd.read_csv(expanded_games_file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{expanded_games_file} not found.\")\n",
    "\n",
    "# Identify unprocessed games\n",
    "unprocessed_games = games_df[games_df[\"home_player_1_id\"].isna()][\"game_id\"].tolist()\n",
    "print(f\"Found {len(unprocessed_games)} unprocessed games.\")\n",
    "\n",
    "# Set threading and batch processing parameters\n",
    "lock = threading.Lock()\n",
    "processed_games = 0\n",
    "batch_size = 100\n",
    "\n",
    "def process_game(game_id):\n",
    "    try:\n",
    "        # print(f\"Processing game ID {game_id}...\")\n",
    "\n",
    "        # Fetch stats for the game\n",
    "        base_stats = fetch_stats(BASE_URL_STATS, game_id)\n",
    "        advanced_stats = fetch_stats(BASE_URL_ADVANCED, game_id)\n",
    "\n",
    "        if not base_stats or not advanced_stats:\n",
    "            print(f\"No stats found for game ID {game_id}. Skipping...\")\n",
    "            return None, game_id\n",
    "\n",
    "        # Convert to DataFrames\n",
    "        base_df = pd.DataFrame(base_stats)\n",
    "        adv_df = pd.DataFrame(advanced_stats)\n",
    "\n",
    "        # Parse minutes played\n",
    "        base_df[\"minutes_played\"] = base_df[\"min\"].apply(parse_minutes)\n",
    "\n",
    "        # Merge base and advanced stats on player ID\n",
    "        base_df[\"player_id\"] = base_df[\"player\"].apply(lambda x: x[\"id\"])\n",
    "        adv_df[\"player_id\"] = adv_df[\"player\"].apply(lambda x: x[\"id\"])\n",
    "        adv_df[\"position\"] = adv_df[\"player\"].apply(lambda x: x.get(\"position\", None))  # Extract position\n",
    "        merged_df = pd.merge(\n",
    "            base_df,\n",
    "            adv_df[[\"player_id\", \"offensive_rating\", \"defensive_rating\", \"usage_percentage\", \"position\"]],\n",
    "            on=\"player_id\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "\n",
    "        # Add team and player full name\n",
    "        merged_df[\"team_id\"] = merged_df[\"team\"].apply(lambda x: x[\"id\"])\n",
    "        merged_df[\"team_name\"] = merged_df[\"team\"].apply(lambda x: x[\"full_name\"])\n",
    "        merged_df[\"full_name\"] = merged_df[\"player\"].apply(lambda x: f\"{x['first_name']} {x['last_name']}\")\n",
    "\n",
    "        # Extract home and away team IDs from the main DataFrame\n",
    "        home_team_id = games_df.loc[games_df[\"game_id\"] == game_id, \"home_team_id\"].values[0]\n",
    "        away_team_id = games_df.loc[games_df[\"game_id\"] == game_id, \"visitor_team_id\"].values[0]\n",
    "\n",
    "        # Split into home and away players and select top 12 by minutes played\n",
    "        home_players = merged_df[merged_df[\"team_id\"] == home_team_id].nlargest(12, \"minutes_played\")\n",
    "        away_players = merged_df[merged_df[\"team_id\"] == away_team_id].nlargest(12, \"minutes_played\")\n",
    "\n",
    "        # Create a dictionary to store processed player data\n",
    "        player_data = {}\n",
    "        for i in range(1, 13):\n",
    "            for team, players in [(\"home\", home_players), (\"away\", away_players)]:\n",
    "                if i <= len(players):\n",
    "                    player_data[f\"{team}_player_{i}_id\"] = players.iloc[i - 1][\"player_id\"]\n",
    "                    player_data[f\"{team}_player_{i}_name\"] = players.iloc[i - 1][\"full_name\"]\n",
    "                    player_data[f\"{team}_player_{i}_minutes\"] = players.iloc[i - 1][\"minutes_played\"]\n",
    "                    player_data[f\"{team}_player_{i}_position\"] = players.iloc[i - 1][\"position\"]\n",
    "                    player_data[f\"{team}_player_{i}_off_rating\"] = players.iloc[i - 1][\"offensive_rating\"]\n",
    "                    player_data[f\"{team}_player_{i}_def_rating\"] = players.iloc[i - 1][\"defensive_rating\"]\n",
    "                    player_data[f\"{team}_player_{i}_usage\"] = players.iloc[i - 1][\"usage_percentage\"]\n",
    "                else:\n",
    "                    player_data[f\"{team}_player_{i}_id\"] = None\n",
    "                    player_data[f\"{team}_player_{i}_name\"] = None\n",
    "                    player_data[f\"{team}_player_{i}_minutes\"] = None\n",
    "                    player_data[f\"{team}_player_{i}_position\"] = None\n",
    "                    player_data[f\"{team}_player_{i}_off_rating\"] = None\n",
    "                    player_data[f\"{team}_player_{i}_def_rating\"] = None\n",
    "                    player_data[f\"{team}_player_{i}_usage\"] = None\n",
    "\n",
    "        # print(f\"Finished processing game ID {game_id}.\")\n",
    "        return player_data, game_id\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing game {game_id}: {e}\")\n",
    "        return None, game_id\n",
    "# Function to update the DataFrame with processed game data\n",
    "def update_games_df(game_data, game_id):\n",
    "    global games_df\n",
    "    with lock:\n",
    "        for key, value in game_data.items():\n",
    "            games_df.loc[games_df[\"game_id\"] == game_id, key] = value\n",
    "\n",
    "# Function to save progress to a file\n",
    "def save_progress():\n",
    "    global games_df\n",
    "    with lock:\n",
    "        games_df.to_csv(expanded_games_file, index=False)\n",
    "        print(f\"Progress saved at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ThreadPoolExecutor for processing games\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = executor.map(process_game, unprocessed_games)\n",
    "    for game_data, game_id in futures:\n",
    "        if game_data:\n",
    "            update_games_df(game_data, game_id)\n",
    "            processed_games += 1\n",
    "            if processed_games % batch_size == 0:\n",
    "                save_progress()\n",
    "\n",
    "# Final save\n",
    "save_progress()\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created playerBio.csv with player_Ids normalized, heights, and weights for quick lookup during static tensor creation\n",
    "GAME_DATA_FILE = \"expanded_games_2003_2023.csv\"\n",
    "PLAYER_BIO_FILE = \"playerBio.csv\"\n",
    "\n",
    "# Load the game data\n",
    "games_df = pd.read_csv(GAME_DATA_FILE)\n",
    "\n",
    "# Extract player ID columns for both home and away teams\n",
    "player_columns = [f\"{team}_player_{i}_id\" for team in [\"home\", \"away\"] for i in range(1, 13)]\n",
    "player_ids = games_df[player_columns].stack().dropna().astype(int).unique()  # Stack, drop NaN, ensure integers\n",
    "\n",
    "# Create a DataFrame for unique player IDs\n",
    "player_bio_df = pd.DataFrame(player_ids, columns=[\"player_id\"])\n",
    "\n",
    "# Save the unique player IDs to playerBio.csv\n",
    "player_bio_df.to_csv(PLAYER_BIO_FILE, index=False)\n",
    "print(f\"Created {PLAYER_BIO_FILE} with {len(player_bio_df)} unique player IDs.\")\n",
    "\n",
    "# Normalize player IDs\n",
    "player_bio_df[\"normalized_id\"] = range(len(player_bio_df))  # Assign normalized IDs sequentially\n",
    "\n",
    "# Save the updated player bio file\n",
    "player_bio_df.to_csv(PLAYER_BIO_FILE, index=False)\n",
    "print(f\"Updated {PLAYER_BIO_FILE} with normalized player IDs.\")\n",
    "print(player_bio_df.head())\n",
    "\n",
    "API_KEY = \"\"\n",
    "PLAYER_API_URL = \"https://api.balldontlie.io/v1/players\"\n",
    "\n",
    "# Load playerBio.csv\n",
    "player_bio_df = pd.read_csv(PLAYER_BIO_FILE)\n",
    "\n",
    "# Add height and weight columns if they do not exist\n",
    "if \"height\" not in player_bio_df.columns:\n",
    "    player_bio_df[\"height\"] = None\n",
    "if \"weight\" not in player_bio_df.columns:\n",
    "    player_bio_df[\"weight\"] = None\n",
    "\n",
    "# Get all player_ids that still need height and weight\n",
    "players_to_fetch = player_bio_df[player_bio_df[\"height\"].isna()][\"player_id\"].tolist()\n",
    "\n",
    "# Batch size for saving progress\n",
    "batch_size = 50\n",
    "\n",
    "# Loop over player IDs\n",
    "for idx, player_id in enumerate(players_to_fetch, start=1):\n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.get(f\"{PLAYER_API_URL}?player_ids[]={player_id}\", headers={\"Authorization\": API_KEY})\n",
    "        if response.status_code == 200:\n",
    "            player_data = response.json()\n",
    "\n",
    "            # Check if the API response contains valid data\n",
    "            if \"data\" in player_data and len(player_data[\"data\"]) > 0:\n",
    "                player = player_data[\"data\"][0]\n",
    "\n",
    "                # Parse height\n",
    "                height_str = player.get(\"height\", \"0\")\n",
    "                if \"-\" in height_str:  # Format is \"6-1\"\n",
    "                    feet, inches = map(int, height_str.split(\"-\"))\n",
    "                    height = feet * 12 + inches\n",
    "                elif height_str.isdigit():  # Format is \"6\"\n",
    "                    height = int(height_str) * 12\n",
    "                else:\n",
    "                    height = 0  # Default for invalid/missing height\n",
    "\n",
    "                # Parse weight\n",
    "                weight = int(player.get(\"weight\", 0))\n",
    "\n",
    "                # Update playerBio DataFrame\n",
    "                player_bio_df.loc[player_bio_df[\"player_id\"] == player_id, \"height\"] = height\n",
    "                player_bio_df.loc[player_bio_df[\"player_id\"] == player_id, \"weight\"] = weight\n",
    "            else:\n",
    "                print(f\"No valid data for player ID {player_id}.\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for player ID {player_id}: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for player ID {player_id}: {e}\")\n",
    "\n",
    "    # Save progress every 50 players\n",
    "    if idx % batch_size == 0:\n",
    "        player_bio_df.to_csv(PLAYER_BIO_FILE, index=False)\n",
    "        print(f\"Saved progress after processing {idx} players.\")\n",
    "\n",
    "    # Delay to avoid hitting rate limits\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Final save\n",
    "player_bio_df.to_csv(PLAYER_BIO_FILE, index=False)\n",
    "print(\"Completed fetching height and weight for all players. Saved final progress.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensor for a single game example\n",
    "# -----------------------------------------------------------\n",
    "# This block demonstrates the process of generating and saving static tensors for a single game.\n",
    "# Static tensors represent team-level features (e.g., player stats) that do not change during the game.\n",
    "# The tensors are saved in a structured directory format for easy access during model training.\n",
    "# Key steps include:\n",
    "# 1. Defining the storage structure for tensors.\n",
    "# 2. Fetching player-specific static features (e.g., height, weight, minutes played).\n",
    "# 3. Normalizing and converting player data into tensors.\n",
    "# 4. Saving the tensors to disk with season-specific organization.\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# File for player height and weight lookup\n",
    "PLAYER_BIO_FILE = \"playerBio.csv\"\n",
    "\n",
    "# Directory for saving static tensors\n",
    "TENSOR_DIR = \"static_game_tensors\"\n",
    "os.makedirs(TENSOR_DIR, exist_ok=True)\n",
    "\n",
    "# Create the player bio file if it doesn't exist\n",
    "if not os.path.exists(PLAYER_BIO_FILE):\n",
    "    pd.DataFrame(columns=[\"player_id\", \"height\", \"weight\"]).to_csv(PLAYER_BIO_FILE, index=False)\n",
    "\n",
    "def fetch_or_lookup_player_stats(player_id):\n",
    "    \"\"\"\n",
    "    Fetch the player's height and weight from the lookup file or API.\n",
    "    \"\"\"\n",
    "    player_bio = pd.read_csv(PLAYER_BIO_FILE)\n",
    "    if player_id in player_bio[\"player_id\"].values:\n",
    "        player_row = player_bio[player_bio[\"player_id\"] == player_id].iloc[0]\n",
    "        return {\"height\": player_row[\"height\"], \"weight\": player_row[\"weight\"]}\n",
    "    else:\n",
    "        # Fallback for height/weight API lookup if not in the CSV\n",
    "        return {\"height\": 72, \"weight\": 200}  # Default values for height/weight\n",
    "\n",
    "def process_team_static(game_row, team_prefix):\n",
    "    \"\"\"\n",
    "    Process a team's static features for saving.\n",
    "    \"\"\"\n",
    "    players = []\n",
    "    for i in range(1, 13):\n",
    "        player_id = game_row[f\"{team_prefix}_player_{i}_id\"]\n",
    "        player_data = {\n",
    "            \"player_id\": int(player_id) if not pd.isna(player_id) else None,\n",
    "            \"minutes\": game_row[f\"{team_prefix}_player_{i}_minutes\"],\n",
    "            \"off_rating\": game_row[f\"{team_prefix}_player_{i}_off_rating\"],\n",
    "            \"def_rating\": game_row[f\"{team_prefix}_player_{i}_def_rating\"],\n",
    "            \"usage\": game_row[f\"{team_prefix}_player_{i}_usage\"],\n",
    "        }\n",
    "        if player_data[\"player_id\"] is not None:\n",
    "            stats = fetch_or_lookup_player_stats(player_data[\"player_id\"])\n",
    "            player_data.update(stats)\n",
    "        players.append(player_data)\n",
    "    \n",
    "    # Normalize static features\n",
    "    numeric_features = [\"minutes\", \"off_rating\", \"def_rating\", \"usage\", \"height\", \"weight\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    numeric_data = [[player[f] for f in numeric_features] for player in players if player[\"player_id\"] is not None]\n",
    "    if len(numeric_data) > 0:\n",
    "        scaler.fit(numeric_data)\n",
    "        normalized_data = scaler.transform(numeric_data)\n",
    "    else:\n",
    "        normalized_data = []\n",
    "\n",
    "    team_tensor = []\n",
    "    for i, player in enumerate(players):\n",
    "        if player[\"player_id\"] is None:\n",
    "            continue\n",
    "        numeric_values = [player[f] if f in player and player[f] is not None else 0 for f in numeric_features]\n",
    "        normalized_features = scaler.transform([numeric_values])[0] if len(numeric_data) > 0 else [0] * len(numeric_features)\n",
    "        static_tensor = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "        team_tensor.append(static_tensor)\n",
    "    \n",
    "    # Pad to ensure 12 players\n",
    "    while len(team_tensor) < 12:\n",
    "        team_tensor.append(torch.zeros_like(team_tensor[0]))\n",
    "\n",
    "    return torch.stack(team_tensor)\n",
    "\n",
    "def save_static_tensors(game_row, home_tensor, away_tensor):\n",
    "    \"\"\"\n",
    "    Save home and away static tensors for a game in season-specific folders.\n",
    "    \"\"\"\n",
    "    season = game_row[\"season\"]  # Extract season\n",
    "    season_dir = os.path.join(TENSOR_DIR, f\"season_{season}\")\n",
    "    os.makedirs(season_dir, exist_ok=True)  # Create season directory if it doesn't exist\n",
    "\n",
    "    # Save tensors\n",
    "    game_id = game_row[\"game_id\"]\n",
    "    home_path = os.path.join(season_dir, f\"{game_id}_home_static.pt\")\n",
    "    away_path = os.path.join(season_dir, f\"{game_id}_away_static.pt\")\n",
    "    torch.save(home_tensor, home_path)\n",
    "    torch.save(away_tensor, away_path)\n",
    "    print(f\"Saved static tensors for game {game_id} in season {season}: Home -> {home_path}, Away -> {away_path}\")\n",
    "\n",
    "# Example: Process and save static tensors for a single game\n",
    "game_row = games_df[games_df[\"game_id\"] == game_id].iloc[0]\n",
    "home_static_tensor = process_team_static(game_row, \"home\")\n",
    "away_static_tensor = process_team_static(game_row, \"away\")\n",
    "save_static_tensors(game_row, home_static_tensor, away_static_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'expanded_games_2003_2023.csv' loaded successfully. Number of rows: 26947\n",
      "Saved static tensors for game 15486 in season 2003: Home -> static_game_tensors_redo/season_2003/15486_home_static.pt, Away -> static_game_tensors_redo/season_2003/15486_away_static.pt\n",
      "Saved static tensors for game 15487 in season 2003: Home -> static_game_tensors_redo/season_2003/15487_home_static.pt, Away -> static_game_tensors_redo/season_2003/15487_away_static.pt\n",
      "Saved static tensors for game 15778 in season 2003: Home -> static_game_tensors_redo/season_2003/15778_home_static.pt, Away -> static_game_tensors_redo/season_2003/15778_away_static.pt\n",
      "Saved static tensors for game 15488 in season 2003: Home -> static_game_tensors_redo/season_2003/15488_home_static.pt, Away -> static_game_tensors_redo/season_2003/15488_away_static.pt\n",
      "Saved static tensors for game 15489 in season 2003: Home -> static_game_tensors_redo/season_2003/15489_home_static.pt, Away -> static_game_tensors_redo/season_2003/15489_away_static.pt\n",
      "Saved static tensors for game 15490 in season 2003: Home -> static_game_tensors_redo/season_2003/15490_home_static.pt, Away -> static_game_tensors_redo/season_2003/15490_away_static.pt\n",
      "Saved static tensors for game 15779 in season 2003: Home -> static_game_tensors_redo/season_2003/15779_home_static.pt, Away -> static_game_tensors_redo/season_2003/15779_away_static.pt\n",
      "Saved static tensors for game 15780 in season 2003: Home -> static_game_tensors_redo/season_2003/15780_home_static.pt, Away -> static_game_tensors_redo/season_2003/15780_away_static.pt\n",
      "Saved static tensors for game 15781 in season 2003: Home -> static_game_tensors_redo/season_2003/15781_home_static.pt, Away -> static_game_tensors_redo/season_2003/15781_away_static.pt\n",
      "Saved static tensors for game 15945 in season 2003: Home -> static_game_tensors_redo/season_2003/15945_home_static.pt, Away -> static_game_tensors_redo/season_2003/15945_away_static.pt\n",
      "Saved static tensors for game 15946 in season 2003: Home -> static_game_tensors_redo/season_2003/15946_home_static.pt, Away -> static_game_tensors_redo/season_2003/15946_away_static.pt\n",
      "Saved static tensors for game 15947 in season 2003: Home -> static_game_tensors_redo/season_2003/15947_home_static.pt, Away -> static_game_tensors_redo/season_2003/15947_away_static.pt\n",
      "Saved static tensors for game 16020 in season 2003: Home -> static_game_tensors_redo/season_2003/16020_home_static.pt, Away -> static_game_tensors_redo/season_2003/16020_away_static.pt\n",
      "Saved static tensors for game 16146 in season 2003: Home -> static_game_tensors_redo/season_2003/16146_home_static.pt, Away -> static_game_tensors_redo/season_2003/16146_away_static.pt\n",
      "Saved static tensors for game 16147 in season 2003: Home -> static_game_tensors_redo/season_2003/16147_home_static.pt, Away -> static_game_tensors_redo/season_2003/16147_away_static.pt\n",
      "Saved static tensors for game 16277 in season 2003: Home -> static_game_tensors_redo/season_2003/16277_home_static.pt, Away -> static_game_tensors_redo/season_2003/16277_away_static.pt\n",
      "Saved static tensors for game 16394 in season 2003: Home -> static_game_tensors_redo/season_2003/16394_home_static.pt, Away -> static_game_tensors_redo/season_2003/16394_away_static.pt\n",
      "Saved static tensors for game 16573 in season 2003: Home -> static_game_tensors_redo/season_2003/16573_home_static.pt, Away -> static_game_tensors_redo/season_2003/16573_away_static.pt\n",
      "Saved static tensors for game 15782 in season 2003: Home -> static_game_tensors_redo/season_2003/15782_home_static.pt, Away -> static_game_tensors_redo/season_2003/15782_away_static.pt\n",
      "Saved static tensors for game 15948 in season 2003: Home -> static_game_tensors_redo/season_2003/15948_home_static.pt, Away -> static_game_tensors_redo/season_2003/15948_away_static.pt\n",
      "Saved static tensors for game 16021 in season 2003: Home -> static_game_tensors_redo/season_2003/16021_home_static.pt, Away -> static_game_tensors_redo/season_2003/16021_away_static.pt\n",
      "Saved static tensors for game 16148 in season 2003: Home -> static_game_tensors_redo/season_2003/16148_home_static.pt, Away -> static_game_tensors_redo/season_2003/16148_away_static.pt\n",
      "Saved static tensors for game 16278 in season 2003: Home -> static_game_tensors_redo/season_2003/16278_home_static.pt, Away -> static_game_tensors_redo/season_2003/16278_away_static.pt\n",
      "Saved static tensors for game 16395 in season 2003: Home -> static_game_tensors_redo/season_2003/16395_home_static.pt, Away -> static_game_tensors_redo/season_2003/16395_away_static.pt\n",
      "Saved static tensors for game 16574 in season 2003: Home -> static_game_tensors_redo/season_2003/16574_home_static.pt, Away -> static_game_tensors_redo/season_2003/16574_away_static.pt\n",
      "Saved static tensors for game 16707 in season 2003: Home -> static_game_tensors_redo/season_2003/16707_home_static.pt, Away -> static_game_tensors_redo/season_2003/16707_away_static.pt\n",
      "Saved static tensors for game 15491 in season 2003: Home -> static_game_tensors_redo/season_2003/15491_home_static.pt, Away -> static_game_tensors_redo/season_2003/15491_away_static.pt\n",
      "Saved static tensors for game 15783 in season 2003: Home -> static_game_tensors_redo/season_2003/15783_home_static.pt, Away -> static_game_tensors_redo/season_2003/15783_away_static.pt\n",
      "Saved static tensors for game 15949 in season 2003: Home -> static_game_tensors_redo/season_2003/15949_home_static.pt, Away -> static_game_tensors_redo/season_2003/15949_away_static.pt\n",
      "Saved static tensors for game 15950 in season 2003: Home -> static_game_tensors_redo/season_2003/15950_home_static.pt, Away -> static_game_tensors_redo/season_2003/15950_away_static.pt\n",
      "Saved static tensors for game 16022 in season 2003: Home -> static_game_tensors_redo/season_2003/16022_home_static.pt, Away -> static_game_tensors_redo/season_2003/16022_away_static.pt\n",
      "Saved static tensors for game 16023 in season 2003: Home -> static_game_tensors_redo/season_2003/16023_home_static.pt, Away -> static_game_tensors_redo/season_2003/16023_away_static.pt\n",
      "Saved static tensors for game 16149 in season 2003: Home -> static_game_tensors_redo/season_2003/16149_home_static.pt, Away -> static_game_tensors_redo/season_2003/16149_away_static.pt\n",
      "Saved static tensors for game 16150 in season 2003: Home -> static_game_tensors_redo/season_2003/16150_home_static.pt, Away -> static_game_tensors_redo/season_2003/16150_away_static.pt\n",
      "Saved static tensors for game 16279 in season 2003: Home -> static_game_tensors_redo/season_2003/16279_home_static.pt, Away -> static_game_tensors_redo/season_2003/16279_away_static.pt\n",
      "Saved static tensors for game 16396 in season 2003: Home -> static_game_tensors_redo/season_2003/16396_home_static.pt, Away -> static_game_tensors_redo/season_2003/16396_away_static.pt\n",
      "Saved static tensors for game 16575 in season 2003: Home -> static_game_tensors_redo/season_2003/16575_home_static.pt, Away -> static_game_tensors_redo/season_2003/16575_away_static.pt\n",
      "Saved static tensors for game 16708 in season 2003: Home -> static_game_tensors_redo/season_2003/16708_home_static.pt, Away -> static_game_tensors_redo/season_2003/16708_away_static.pt\n",
      "Saved static tensors for game 16834 in season 2003: Home -> static_game_tensors_redo/season_2003/16834_home_static.pt, Away -> static_game_tensors_redo/season_2003/16834_away_static.pt\n",
      "Saved static tensors for game 15784 in season 2003: Home -> static_game_tensors_redo/season_2003/15784_home_static.pt, Away -> static_game_tensors_redo/season_2003/15784_away_static.pt\n",
      "Saved static tensors for game 15785 in season 2003: Home -> static_game_tensors_redo/season_2003/15785_home_static.pt, Away -> static_game_tensors_redo/season_2003/15785_away_static.pt\n",
      "Saved static tensors for game 15951 in season 2003: Home -> static_game_tensors_redo/season_2003/15951_home_static.pt, Away -> static_game_tensors_redo/season_2003/15951_away_static.pt\n",
      "Saved static tensors for game 16024 in season 2003: Home -> static_game_tensors_redo/season_2003/16024_home_static.pt, Away -> static_game_tensors_redo/season_2003/16024_away_static.pt\n",
      "Saved static tensors for game 16151 in season 2003: Home -> static_game_tensors_redo/season_2003/16151_home_static.pt, Away -> static_game_tensors_redo/season_2003/16151_away_static.pt\n",
      "Saved static tensors for game 16397 in season 2003: Home -> static_game_tensors_redo/season_2003/16397_home_static.pt, Away -> static_game_tensors_redo/season_2003/16397_away_static.pt\n",
      "Saved static tensors for game 16709 in season 2003: Home -> static_game_tensors_redo/season_2003/16709_home_static.pt, Away -> static_game_tensors_redo/season_2003/16709_away_static.pt\n",
      "Saved static tensors for game 16835 in season 2003: Home -> static_game_tensors_redo/season_2003/16835_home_static.pt, Away -> static_game_tensors_redo/season_2003/16835_away_static.pt\n",
      "Saved static tensors for game 15952 in season 2003: Home -> static_game_tensors_redo/season_2003/15952_home_static.pt, Away -> static_game_tensors_redo/season_2003/15952_away_static.pt\n",
      "Saved static tensors for game 16025 in season 2003: Home -> static_game_tensors_redo/season_2003/16025_home_static.pt, Away -> static_game_tensors_redo/season_2003/16025_away_static.pt\n",
      "Saved static tensors for game 16152 in season 2003: Home -> static_game_tensors_redo/season_2003/16152_home_static.pt, Away -> static_game_tensors_redo/season_2003/16152_away_static.pt\n",
      "Saved static tensors for game 16398 in season 2003: Home -> static_game_tensors_redo/season_2003/16398_home_static.pt, Away -> static_game_tensors_redo/season_2003/16398_away_static.pt\n",
      "Saved static tensors for game 15492 in season 2003: Home -> static_game_tensors_redo/season_2003/15492_home_static.pt, Away -> static_game_tensors_redo/season_2003/15492_away_static.pt\n",
      "Saved static tensors for game 15786 in season 2003: Home -> static_game_tensors_redo/season_2003/15786_home_static.pt, Away -> static_game_tensors_redo/season_2003/15786_away_static.pt\n",
      "Saved static tensors for game 15953 in season 2003: Home -> static_game_tensors_redo/season_2003/15953_home_static.pt, Away -> static_game_tensors_redo/season_2003/15953_away_static.pt\n",
      "Saved static tensors for game 16026 in season 2003: Home -> static_game_tensors_redo/season_2003/16026_home_static.pt, Away -> static_game_tensors_redo/season_2003/16026_away_static.pt\n",
      "Saved static tensors for game 16153 in season 2003: Home -> static_game_tensors_redo/season_2003/16153_home_static.pt, Away -> static_game_tensors_redo/season_2003/16153_away_static.pt\n",
      "Saved static tensors for game 16280 in season 2003: Home -> static_game_tensors_redo/season_2003/16280_home_static.pt, Away -> static_game_tensors_redo/season_2003/16280_away_static.pt\n",
      "Saved static tensors for game 16399 in season 2003: Home -> static_game_tensors_redo/season_2003/16399_home_static.pt, Away -> static_game_tensors_redo/season_2003/16399_away_static.pt\n",
      "Saved static tensors for game 16576 in season 2003: Home -> static_game_tensors_redo/season_2003/16576_home_static.pt, Away -> static_game_tensors_redo/season_2003/16576_away_static.pt\n",
      "Saved static tensors for game 16710 in season 2003: Home -> static_game_tensors_redo/season_2003/16710_home_static.pt, Away -> static_game_tensors_redo/season_2003/16710_away_static.pt\n",
      "Saved static tensors for game 16836 in season 2003: Home -> static_game_tensors_redo/season_2003/16836_home_static.pt, Away -> static_game_tensors_redo/season_2003/16836_away_static.pt\n",
      "Saved static tensors for game 15787 in season 2003: Home -> static_game_tensors_redo/season_2003/15787_home_static.pt, Away -> static_game_tensors_redo/season_2003/15787_away_static.pt\n",
      "Saved static tensors for game 16027 in season 2003: Home -> static_game_tensors_redo/season_2003/16027_home_static.pt, Away -> static_game_tensors_redo/season_2003/16027_away_static.pt\n",
      "Saved static tensors for game 16577 in season 2003: Home -> static_game_tensors_redo/season_2003/16577_home_static.pt, Away -> static_game_tensors_redo/season_2003/16577_away_static.pt\n",
      "Saved static tensors for game 15493 in season 2003: Home -> static_game_tensors_redo/season_2003/15493_home_static.pt, Away -> static_game_tensors_redo/season_2003/15493_away_static.pt\n",
      "Saved static tensors for game 15494 in season 2003: Home -> static_game_tensors_redo/season_2003/15494_home_static.pt, Away -> static_game_tensors_redo/season_2003/15494_away_static.pt\n",
      "Saved static tensors for game 15788 in season 2003: Home -> static_game_tensors_redo/season_2003/15788_home_static.pt, Away -> static_game_tensors_redo/season_2003/15788_away_static.pt\n",
      "Saved static tensors for game 15954 in season 2003: Home -> static_game_tensors_redo/season_2003/15954_home_static.pt, Away -> static_game_tensors_redo/season_2003/15954_away_static.pt\n",
      "Saved static tensors for game 16028 in season 2003: Home -> static_game_tensors_redo/season_2003/16028_home_static.pt, Away -> static_game_tensors_redo/season_2003/16028_away_static.pt\n",
      "Saved static tensors for game 16029 in season 2003: Home -> static_game_tensors_redo/season_2003/16029_home_static.pt, Away -> static_game_tensors_redo/season_2003/16029_away_static.pt\n",
      "Saved static tensors for game 16154 in season 2003: Home -> static_game_tensors_redo/season_2003/16154_home_static.pt, Away -> static_game_tensors_redo/season_2003/16154_away_static.pt\n",
      "Saved static tensors for game 16281 in season 2003: Home -> static_game_tensors_redo/season_2003/16281_home_static.pt, Away -> static_game_tensors_redo/season_2003/16281_away_static.pt\n",
      "Saved static tensors for game 16400 in season 2003: Home -> static_game_tensors_redo/season_2003/16400_home_static.pt, Away -> static_game_tensors_redo/season_2003/16400_away_static.pt\n",
      "Saved static tensors for game 16578 in season 2003: Home -> static_game_tensors_redo/season_2003/16578_home_static.pt, Away -> static_game_tensors_redo/season_2003/16578_away_static.pt\n",
      "Saved static tensors for game 16711 in season 2003: Home -> static_game_tensors_redo/season_2003/16711_home_static.pt, Away -> static_game_tensors_redo/season_2003/16711_away_static.pt\n",
      "Saved static tensors for game 16837 in season 2003: Home -> static_game_tensors_redo/season_2003/16837_home_static.pt, Away -> static_game_tensors_redo/season_2003/16837_away_static.pt\n",
      "Saved static tensors for game 15495 in season 2003: Home -> static_game_tensors_redo/season_2003/15495_home_static.pt, Away -> static_game_tensors_redo/season_2003/15495_away_static.pt\n",
      "Saved static tensors for game 16030 in season 2003: Home -> static_game_tensors_redo/season_2003/16030_home_static.pt, Away -> static_game_tensors_redo/season_2003/16030_away_static.pt\n",
      "Saved static tensors for game 16155 in season 2003: Home -> static_game_tensors_redo/season_2003/16155_home_static.pt, Away -> static_game_tensors_redo/season_2003/16155_away_static.pt\n",
      "Saved static tensors for game 16282 in season 2003: Home -> static_game_tensors_redo/season_2003/16282_home_static.pt, Away -> static_game_tensors_redo/season_2003/16282_away_static.pt\n",
      "Saved static tensors for game 16401 in season 2003: Home -> static_game_tensors_redo/season_2003/16401_home_static.pt, Away -> static_game_tensors_redo/season_2003/16401_away_static.pt\n",
      "Saved static tensors for game 16579 in season 2003: Home -> static_game_tensors_redo/season_2003/16579_home_static.pt, Away -> static_game_tensors_redo/season_2003/16579_away_static.pt\n",
      "Saved static tensors for game 16712 in season 2003: Home -> static_game_tensors_redo/season_2003/16712_home_static.pt, Away -> static_game_tensors_redo/season_2003/16712_away_static.pt\n",
      "Saved static tensors for game 16838 in season 2003: Home -> static_game_tensors_redo/season_2003/16838_home_static.pt, Away -> static_game_tensors_redo/season_2003/16838_away_static.pt\n",
      "Saved static tensors for game 16156 in season 2003: Home -> static_game_tensors_redo/season_2003/16156_home_static.pt, Away -> static_game_tensors_redo/season_2003/16156_away_static.pt\n",
      "Saved static tensors for game 16283 in season 2003: Home -> static_game_tensors_redo/season_2003/16283_home_static.pt, Away -> static_game_tensors_redo/season_2003/16283_away_static.pt\n",
      "Saved static tensors for game 16402 in season 2003: Home -> static_game_tensors_redo/season_2003/16402_home_static.pt, Away -> static_game_tensors_redo/season_2003/16402_away_static.pt\n",
      "Saved static tensors for game 16580 in season 2003: Home -> static_game_tensors_redo/season_2003/16580_home_static.pt, Away -> static_game_tensors_redo/season_2003/16580_away_static.pt\n",
      "Saved static tensors for game 16713 in season 2003: Home -> static_game_tensors_redo/season_2003/16713_home_static.pt, Away -> static_game_tensors_redo/season_2003/16713_away_static.pt\n",
      "Saved static tensors for game 16157 in season 2003: Home -> static_game_tensors_redo/season_2003/16157_home_static.pt, Away -> static_game_tensors_redo/season_2003/16157_away_static.pt\n",
      "Saved static tensors for game 16284 in season 2003: Home -> static_game_tensors_redo/season_2003/16284_home_static.pt, Away -> static_game_tensors_redo/season_2003/16284_away_static.pt\n",
      "Saved static tensors for game 16403 in season 2003: Home -> static_game_tensors_redo/season_2003/16403_home_static.pt, Away -> static_game_tensors_redo/season_2003/16403_away_static.pt\n",
      "Saved static tensors for game 16581 in season 2003: Home -> static_game_tensors_redo/season_2003/16581_home_static.pt, Away -> static_game_tensors_redo/season_2003/16581_away_static.pt\n",
      "Saved static tensors for game 16714 in season 2003: Home -> static_game_tensors_redo/season_2003/16714_home_static.pt, Away -> static_game_tensors_redo/season_2003/16714_away_static.pt\n",
      "Saved static tensors for game 15496 in season 2003: Home -> static_game_tensors_redo/season_2003/15496_home_static.pt, Away -> static_game_tensors_redo/season_2003/15496_away_static.pt\n",
      "Saved static tensors for game 16031 in season 2003: Home -> static_game_tensors_redo/season_2003/16031_home_static.pt, Away -> static_game_tensors_redo/season_2003/16031_away_static.pt\n",
      "Saved static tensors for game 16158 in season 2003: Home -> static_game_tensors_redo/season_2003/16158_home_static.pt, Away -> static_game_tensors_redo/season_2003/16158_away_static.pt\n",
      "Saved static tensors for game 16285 in season 2003: Home -> static_game_tensors_redo/season_2003/16285_home_static.pt, Away -> static_game_tensors_redo/season_2003/16285_away_static.pt\n",
      "Saved static tensors for game 16404 in season 2003: Home -> static_game_tensors_redo/season_2003/16404_home_static.pt, Away -> static_game_tensors_redo/season_2003/16404_away_static.pt\n",
      "Saved static tensors for game 16582 in season 2003: Home -> static_game_tensors_redo/season_2003/16582_home_static.pt, Away -> static_game_tensors_redo/season_2003/16582_away_static.pt\n",
      "Saved static tensors for game 16404 in season 2003: Home -> static_game_tensors_redo/season_2003/16404_home_static.pt, Away -> static_game_tensors_redo/season_2003/16404_away_static.pt\n",
      "Saved static tensors for game 16715 in season 2003: Home -> static_game_tensors_redo/season_2003/16715_home_static.pt, Away -> static_game_tensors_redo/season_2003/16715_away_static.pt\n",
      "Saved static tensors for game 16839 in season 2003: Home -> static_game_tensors_redo/season_2003/16839_home_static.pt, Away -> static_game_tensors_redo/season_2003/16839_away_static.pt\n",
      "Saved static tensors for game 16285 in season 2003: Home -> static_game_tensors_redo/season_2003/16285_home_static.pt, Away -> static_game_tensors_redo/season_2003/16285_away_static.pt\n",
      "Saved static tensors for game 16158 in season 2003: Home -> static_game_tensors_redo/season_2003/16158_home_static.pt, Away -> static_game_tensors_redo/season_2003/16158_away_static.pt\n",
      "Saved static tensors for game 16031 in season 2003: Home -> static_game_tensors_redo/season_2003/16031_home_static.pt, Away -> static_game_tensors_redo/season_2003/16031_away_static.pt\n",
      "Saved static tensors for game 16032 in season 2003: Home -> static_game_tensors_redo/season_2003/16032_home_static.pt, Away -> static_game_tensors_redo/season_2003/16032_away_static.pt\n",
      "Saved static tensors for game 16716 in season 2003: Home -> static_game_tensors_redo/season_2003/16716_home_static.pt, Away -> static_game_tensors_redo/season_2003/16716_away_static.pt\n",
      "Saved static tensors for game 15497 in season 2003: Home -> static_game_tensors_redo/season_2003/15497_home_static.pt, Away -> static_game_tensors_redo/season_2003/15497_away_static.pt\n",
      "Saved static tensors for game 16840 in season 2003: Home -> static_game_tensors_redo/season_2003/16840_home_static.pt, Away -> static_game_tensors_redo/season_2003/16840_away_static.pt\n",
      "Saved static tensors for game 16406 in season 2003: Home -> static_game_tensors_redo/season_2003/16406_home_static.pt, Away -> static_game_tensors_redo/season_2003/16406_away_static.pt\n",
      "Saved static tensors for game 16405 in season 2003: Home -> static_game_tensors_redo/season_2003/16405_home_static.pt, Away -> static_game_tensors_redo/season_2003/16405_away_static.pt\n",
      "Saved static tensors for game 16159 in season 2003: Home -> static_game_tensors_redo/season_2003/16159_home_static.pt, Away -> static_game_tensors_redo/season_2003/16159_away_static.pt\n",
      "Saved static tensors for game 16286 in season 2003: Home -> static_game_tensors_redo/season_2003/16286_home_static.pt, Away -> static_game_tensors_redo/season_2003/16286_away_static.pt\n",
      "Saved static tensors for game 16583 in season 2003: Home -> static_game_tensors_redo/season_2003/16583_home_static.pt, Away -> static_game_tensors_redo/season_2003/16583_away_static.pt\n",
      "Saved static tensors for game 16955 in season 2003: Home -> static_game_tensors_redo/season_2003/16955_home_static.pt, Away -> static_game_tensors_redo/season_2003/16955_away_static.pt\n",
      "Saved static tensors for game 16584 in season 2003: Home -> static_game_tensors_redo/season_2003/16584_home_static.pt, Away -> static_game_tensors_redo/season_2003/16584_away_static.pt\n",
      "Saved static tensors for game 16407 in season 2003: Home -> static_game_tensors_redo/season_2003/16407_home_static.pt, Away -> static_game_tensors_redo/season_2003/16407_away_static.pt\n",
      "Saved static tensors for game 16956 in season 2003: Home -> static_game_tensors_redo/season_2003/16956_home_static.pt, Away -> static_game_tensors_redo/season_2003/16956_away_static.pt\n",
      "Saved static tensors for game 15498 in season 2003: Home -> static_game_tensors_redo/season_2003/15498_home_static.pt, Away -> static_game_tensors_redo/season_2003/15498_away_static.pt\n",
      "Saved static tensors for game 16033 in season 2003: Home -> static_game_tensors_redo/season_2003/16033_home_static.pt, Away -> static_game_tensors_redo/season_2003/16033_away_static.pt\n",
      "Saved static tensors for game 16034 in season 2003: Home -> static_game_tensors_redo/season_2003/16034_home_static.pt, Away -> static_game_tensors_redo/season_2003/16034_away_static.pt\n",
      "Saved static tensors for game 16160 in season 2003: Home -> static_game_tensors_redo/season_2003/16160_home_static.pt, Away -> static_game_tensors_redo/season_2003/16160_away_static.pt\n",
      "Saved static tensors for game 16287 in season 2003: Home -> static_game_tensors_redo/season_2003/16287_home_static.pt, Away -> static_game_tensors_redo/season_2003/16287_away_static.pt\n",
      "Saved static tensors for game 16841 in season 2003: Home -> static_game_tensors_redo/season_2003/16841_home_static.pt, Away -> static_game_tensors_redo/season_2003/16841_away_static.pt\n",
      "Saved static tensors for game 16717 in season 2003: Home -> static_game_tensors_redo/season_2003/16717_home_static.pt, Away -> static_game_tensors_redo/season_2003/16717_away_static.pt\n",
      "Saved static tensors for game 16408 in season 2003: Home -> static_game_tensors_redo/season_2003/16408_home_static.pt, Away -> static_game_tensors_redo/season_2003/16408_away_static.pt\n",
      "Saved static tensors for game 16586 in season 2003: Home -> static_game_tensors_redo/season_2003/16586_home_static.pt, Away -> static_game_tensors_redo/season_2003/16586_away_static.pt\n",
      "Saved static tensors for game 16585 in season 2003: Home -> static_game_tensors_redo/season_2003/16585_home_static.pt, Away -> static_game_tensors_redo/season_2003/16585_away_static.pt\n",
      "Saved static tensors for game 16587 in season 2003: Home -> static_game_tensors_redo/season_2003/16587_home_static.pt, Away -> static_game_tensors_redo/season_2003/16587_away_static.pt\n",
      "Saved static tensors for game 16035 in season 2003: Home -> static_game_tensors_redo/season_2003/16035_home_static.pt, Away -> static_game_tensors_redo/season_2003/16035_away_static.pt\n",
      "Saved static tensors for game 16161 in season 2003: Home -> static_game_tensors_redo/season_2003/16161_home_static.pt, Away -> static_game_tensors_redo/season_2003/16161_away_static.pt\n",
      "Saved static tensors for game 16409 in season 2003: Home -> static_game_tensors_redo/season_2003/16409_home_static.pt, Away -> static_game_tensors_redo/season_2003/16409_away_static.pt\n",
      "Saved static tensors for game 16718 in season 2003: Home -> static_game_tensors_redo/season_2003/16718_home_static.pt, Away -> static_game_tensors_redo/season_2003/16718_away_static.pt\n",
      "Saved static tensors for game 17057 in season 2003: Home -> static_game_tensors_redo/season_2003/17057_home_static.pt, Away -> static_game_tensors_redo/season_2003/17057_away_static.pt\n",
      "Saved static tensors for game 16842 in season 2003: Home -> static_game_tensors_redo/season_2003/16842_home_static.pt, Away -> static_game_tensors_redo/season_2003/16842_away_static.pt\n",
      "Saved static tensors for game 16957 in season 2003: Home -> static_game_tensors_redo/season_2003/16957_home_static.pt, Away -> static_game_tensors_redo/season_2003/16957_away_static.pt\n",
      "Saved static tensors for game 15499 in season 2003: Home -> static_game_tensors_redo/season_2003/15499_home_static.pt, Away -> static_game_tensors_redo/season_2003/15499_away_static.pt\n",
      "Saved static tensors for game 16288 in season 2003: Home -> static_game_tensors_redo/season_2003/16288_home_static.pt, Away -> static_game_tensors_redo/season_2003/16288_away_static.pt\n",
      "Saved static tensors for game 15500 in season 2003: Home -> static_game_tensors_redo/season_2003/15500_home_static.pt, Away -> static_game_tensors_redo/season_2003/15500_away_static.pt\n",
      "Saved static tensors for game 16958 in season 2003: Home -> static_game_tensors_redo/season_2003/16958_home_static.pt, Away -> static_game_tensors_redo/season_2003/16958_away_static.pt\n",
      "Saved static tensors for game 16588 in season 2003: Home -> static_game_tensors_redo/season_2003/16588_home_static.pt, Away -> static_game_tensors_redo/season_2003/16588_away_static.pt\n",
      "Saved static tensors for game 16959 in season 2003: Home -> static_game_tensors_redo/season_2003/16959_home_static.pt, Away -> static_game_tensors_redo/season_2003/16959_away_static.pt\n",
      "Saved static tensors for game 16843 in season 2003: Home -> static_game_tensors_redo/season_2003/16843_home_static.pt, Away -> static_game_tensors_redo/season_2003/16843_away_static.pt\n",
      "Saved static tensors for game 16410 in season 2003: Home -> static_game_tensors_redo/season_2003/16410_home_static.pt, Away -> static_game_tensors_redo/season_2003/16410_away_static.pt\n",
      "Saved static tensors for game 15501 in season 2003: Home -> static_game_tensors_redo/season_2003/15501_home_static.pt, Away -> static_game_tensors_redo/season_2003/15501_away_static.pt\n",
      "Saved static tensors for game 16589 in season 2003: Home -> static_game_tensors_redo/season_2003/16589_home_static.pt, Away -> static_game_tensors_redo/season_2003/16589_away_static.pt\n",
      "Saved static tensors for game 17058 in season 2003: Home -> static_game_tensors_redo/season_2003/17058_home_static.pt, Away -> static_game_tensors_redo/season_2003/17058_away_static.pt\n",
      "Saved static tensors for game 16162 in season 2003: Home -> static_game_tensors_redo/season_2003/16162_home_static.pt, Away -> static_game_tensors_redo/season_2003/16162_away_static.pt\n",
      "Saved static tensors for game 16411 in season 2003: Home -> static_game_tensors_redo/season_2003/16411_home_static.pt, Away -> static_game_tensors_redo/season_2003/16411_away_static.pt\n",
      "Saved static tensors for game 16844 in season 2003: Home -> static_game_tensors_redo/season_2003/16844_home_static.pt, Away -> static_game_tensors_redo/season_2003/16844_away_static.pt\n",
      "Saved static tensors for game 15502 in season 2003: Home -> static_game_tensors_redo/season_2003/15502_home_static.pt, Away -> static_game_tensors_redo/season_2003/15502_away_static.pt\n",
      "Saved static tensors for game 16590 in season 2003: Home -> static_game_tensors_redo/season_2003/16590_home_static.pt, Away -> static_game_tensors_redo/season_2003/16590_away_static.pt\n",
      "Saved static tensors for game 16960 in season 2003: Home -> static_game_tensors_redo/season_2003/16960_home_static.pt, Away -> static_game_tensors_redo/season_2003/16960_away_static.pt\n",
      "Saved static tensors for game 16289 in season 2003: Home -> static_game_tensors_redo/season_2003/16289_home_static.pt, Away -> static_game_tensors_redo/season_2003/16289_away_static.pt\n",
      "Saved static tensors for game 15503 in season 2003: Home -> static_game_tensors_redo/season_2003/15503_home_static.pt, Away -> static_game_tensors_redo/season_2003/15503_away_static.pt\n",
      "Saved static tensors for game 16591 in season 2003: Home -> static_game_tensors_redo/season_2003/16591_home_static.pt, Away -> static_game_tensors_redo/season_2003/16591_away_static.pt\n",
      "Saved static tensors for game 16163 in season 2003: Home -> static_game_tensors_redo/season_2003/16163_home_static.pt, Away -> static_game_tensors_redo/season_2003/16163_away_static.pt\n",
      "Saved static tensors for game 17059 in season 2003: Home -> static_game_tensors_redo/season_2003/17059_home_static.pt, Away -> static_game_tensors_redo/season_2003/17059_away_static.pt\n",
      "Saved static tensors for game 16961 in season 2003: Home -> static_game_tensors_redo/season_2003/16961_home_static.pt, Away -> static_game_tensors_redo/season_2003/16961_away_static.pt\n",
      "Saved static tensors for game 16846 in season 2003: Home -> static_game_tensors_redo/season_2003/16846_home_static.pt, Away -> static_game_tensors_redo/season_2003/16846_away_static.pt\n",
      "Saved static tensors for game 16845 in season 2003: Home -> static_game_tensors_redo/season_2003/16845_home_static.pt, Away -> static_game_tensors_redo/season_2003/16845_away_static.pt\n",
      "Saved static tensors for game 16290 in season 2003: Home -> static_game_tensors_redo/season_2003/16290_home_static.pt, Away -> static_game_tensors_redo/season_2003/16290_away_static.pt\n",
      "Saved static tensors for game 16291 in season 2003: Home -> static_game_tensors_redo/season_2003/16291_home_static.pt, Away -> static_game_tensors_redo/season_2003/16291_away_static.pt\n",
      "Saved static tensors for game 16412 in season 2003: Home -> static_game_tensors_redo/season_2003/16412_home_static.pt, Away -> static_game_tensors_redo/season_2003/16412_away_static.pt\n",
      "Saved static tensors for game 17253 in season 2003: Home -> static_game_tensors_redo/season_2003/17253_home_static.pt, Away -> static_game_tensors_redo/season_2003/17253_away_static.pt\n",
      "Saved static tensors for game 17353 in season 2003: Home -> static_game_tensors_redo/season_2003/17353_home_static.pt, Away -> static_game_tensors_redo/season_2003/17353_away_static.pt\n",
      "Saved static tensors for game 17255 in season 2003: Home -> static_game_tensors_redo/season_2003/17255_home_static.pt, Away -> static_game_tensors_redo/season_2003/17255_away_static.pt\n",
      "Saved static tensors for game 16164 in season 2003: Home -> static_game_tensors_redo/season_2003/16164_home_static.pt, Away -> static_game_tensors_redo/season_2003/16164_away_static.pt\n",
      "Saved static tensors for game 17355 in season 2003: Home -> static_game_tensors_redo/season_2003/17355_home_static.pt, Away -> static_game_tensors_redo/season_2003/17355_away_static.pt\n",
      "Saved static tensors for game 17254 in season 2003: Home -> static_game_tensors_redo/season_2003/17254_home_static.pt, Away -> static_game_tensors_redo/season_2003/17254_away_static.pt\n",
      "Saved static tensors for game 16847 in season 2003: Home -> static_game_tensors_redo/season_2003/16847_home_static.pt, Away -> static_game_tensors_redo/season_2003/16847_away_static.pt\n",
      "Saved static tensors for game 16413 in season 2003: Home -> static_game_tensors_redo/season_2003/16413_home_static.pt, Away -> static_game_tensors_redo/season_2003/16413_away_static.pt\n",
      "Saved static tensors for game 16592 in season 2003: Home -> static_game_tensors_redo/season_2003/16592_home_static.pt, Away -> static_game_tensors_redo/season_2003/16592_away_static.pt\n",
      "Saved static tensors for game 17060 in season 2003: Home -> static_game_tensors_redo/season_2003/17060_home_static.pt, Away -> static_game_tensors_redo/season_2003/17060_away_static.pt\n",
      "Saved static tensors for game 17354 in season 2003: Home -> static_game_tensors_redo/season_2003/17354_home_static.pt, Away -> static_game_tensors_redo/season_2003/17354_away_static.pt\n",
      "Saved static tensors for game 16962 in season 2003: Home -> static_game_tensors_redo/season_2003/16962_home_static.pt, Away -> static_game_tensors_redo/season_2003/16962_away_static.pt\n",
      "Saved static tensors for game 15504 in season 2003: Home -> static_game_tensors_redo/season_2003/15504_home_static.pt, Away -> static_game_tensors_redo/season_2003/15504_away_static.pt\n",
      "Saved static tensors for game 16292 in season 2003: Home -> static_game_tensors_redo/season_2003/16292_home_static.pt, Away -> static_game_tensors_redo/season_2003/16292_away_static.pt\n",
      "Saved static tensors for game 17061 in season 2003: Home -> static_game_tensors_redo/season_2003/17061_home_static.pt, Away -> static_game_tensors_redo/season_2003/17061_away_static.pt\n",
      "Saved static tensors for game 17256 in season 2003: Home -> static_game_tensors_redo/season_2003/17256_home_static.pt, Away -> static_game_tensors_redo/season_2003/17256_away_static.pt\n",
      "Saved static tensors for game 15505 in season 2003: Home -> static_game_tensors_redo/season_2003/15505_home_static.pt, Away -> static_game_tensors_redo/season_2003/15505_away_static.pt\n",
      "Saved static tensors for game 17356 in season 2003: Home -> static_game_tensors_redo/season_2003/17356_home_static.pt, Away -> static_game_tensors_redo/season_2003/17356_away_static.pt\n",
      "Saved static tensors for game 16593 in season 2003: Home -> static_game_tensors_redo/season_2003/16593_home_static.pt, Away -> static_game_tensors_redo/season_2003/16593_away_static.pt\n",
      "Saved static tensors for game 16414 in season 2003: Home -> static_game_tensors_redo/season_2003/16414_home_static.pt, Away -> static_game_tensors_redo/season_2003/16414_away_static.pt\n",
      "Saved static tensors for game 16594 in season 2003: Home -> static_game_tensors_redo/season_2003/16594_home_static.pt, Away -> static_game_tensors_redo/season_2003/16594_away_static.pt\n",
      "Saved static tensors for game 17062 in season 2003: Home -> static_game_tensors_redo/season_2003/17062_home_static.pt, Away -> static_game_tensors_redo/season_2003/17062_away_static.pt\n",
      "Saved static tensors for game 17357 in season 2003: Home -> static_game_tensors_redo/season_2003/17357_home_static.pt, Away -> static_game_tensors_redo/season_2003/17357_away_static.pt\n",
      "Saved static tensors for game 17257 in season 2003: Home -> static_game_tensors_redo/season_2003/17257_home_static.pt, Away -> static_game_tensors_redo/season_2003/17257_away_static.pt\n",
      "Saved static tensors for game 16415 in season 2003: Home -> static_game_tensors_redo/season_2003/16415_home_static.pt, Away -> static_game_tensors_redo/season_2003/16415_away_static.pt\n",
      "Saved static tensors for game 15506 in season 2003: Home -> static_game_tensors_redo/season_2003/15506_home_static.pt, Away -> static_game_tensors_redo/season_2003/15506_away_static.pt\n",
      "Saved static tensors for game 17258 in season 2003: Home -> static_game_tensors_redo/season_2003/17258_home_static.pt, Away -> static_game_tensors_redo/season_2003/17258_away_static.pt\n",
      "Saved static tensors for game 17358 in season 2003: Home -> static_game_tensors_redo/season_2003/17358_home_static.pt, Away -> static_game_tensors_redo/season_2003/17358_away_static.pt\n",
      "Saved static tensors for game 15507 in season 2003: Home -> static_game_tensors_redo/season_2003/15507_home_static.pt, Away -> static_game_tensors_redo/season_2003/15507_away_static.pt\n",
      "Saved static tensors for game 17063 in season 2003: Home -> static_game_tensors_redo/season_2003/17063_home_static.pt, Away -> static_game_tensors_redo/season_2003/17063_away_static.pt\n",
      "Saved static tensors for game 16595 in season 2003: Home -> static_game_tensors_redo/season_2003/16595_home_static.pt, Away -> static_game_tensors_redo/season_2003/16595_away_static.pt\n",
      "Saved static tensors for game 17064 in season 2003: Home -> static_game_tensors_redo/season_2003/17064_home_static.pt, Away -> static_game_tensors_redo/season_2003/17064_away_static.pt\n",
      "Saved static tensors for game 15508 in season 2003: Home -> static_game_tensors_redo/season_2003/15508_home_static.pt, Away -> static_game_tensors_redo/season_2003/15508_away_static.pt\n",
      "Saved static tensors for game 16293 in season 2003: Home -> static_game_tensors_redo/season_2003/16293_home_static.pt, Away -> static_game_tensors_redo/season_2003/16293_away_static.pt\n",
      "Saved static tensors for game 17359 in season 2003: Home -> static_game_tensors_redo/season_2003/17359_home_static.pt, Away -> static_game_tensors_redo/season_2003/17359_away_static.pt\n",
      "Saved static tensors for game 16293 in season 2003: Home -> static_game_tensors_redo/season_2003/16293_home_static.pt, Away -> static_game_tensors_redo/season_2003/16293_away_static.pt\n",
      "Saved static tensors for game 17259 in season 2003: Home -> static_game_tensors_redo/season_2003/17259_home_static.pt, Away -> static_game_tensors_redo/season_2003/17259_away_static.pt\n",
      "Saved static tensors for game 16416 in season 2003: Home -> static_game_tensors_redo/season_2003/16416_home_static.pt, Away -> static_game_tensors_redo/season_2003/16416_away_static.pt\n",
      "Saved static tensors for game 16963 in season 2003: Home -> static_game_tensors_redo/season_2003/16963_home_static.pt, Away -> static_game_tensors_redo/season_2003/16963_away_static.pt\n",
      "Saved static tensors for game 17064 in season 2003: Home -> static_game_tensors_redo/season_2003/17064_home_static.pt, Away -> static_game_tensors_redo/season_2003/17064_away_static.pt\n",
      "Saved static tensors for game 16595 in season 2003: Home -> static_game_tensors_redo/season_2003/16595_home_static.pt, Away -> static_game_tensors_redo/season_2003/16595_away_static.pt\n",
      "Saved static tensors for game 15508 in season 2003: Home -> static_game_tensors_redo/season_2003/15508_home_static.pt, Away -> static_game_tensors_redo/season_2003/15508_away_static.pt\n",
      "Saved static tensors for game 17065 in season 2003: Home -> static_game_tensors_redo/season_2003/17065_home_static.pt, Away -> static_game_tensors_redo/season_2003/17065_away_static.pt\n",
      "Saved static tensors for game 17360 in season 2003: Home -> static_game_tensors_redo/season_2003/17360_home_static.pt, Away -> static_game_tensors_redo/season_2003/17360_away_static.pt\n",
      "Saved static tensors for game 16417 in season 2003: Home -> static_game_tensors_redo/season_2003/16417_home_static.pt, Away -> static_game_tensors_redo/season_2003/16417_away_static.pt\n",
      "Saved static tensors for game 16418 in season 2003: Home -> static_game_tensors_redo/season_2003/16418_home_static.pt, Away -> static_game_tensors_redo/season_2003/16418_away_static.pt\n",
      "Saved static tensors for game 16294 in season 2003: Home -> static_game_tensors_redo/season_2003/16294_home_static.pt, Away -> static_game_tensors_redo/season_2003/16294_away_static.pt\n",
      "Saved static tensors for game 16964 in season 2003: Home -> static_game_tensors_redo/season_2003/16964_home_static.pt, Away -> static_game_tensors_redo/season_2003/16964_away_static.pt\n",
      "Saved static tensors for game 17260 in season 2003: Home -> static_game_tensors_redo/season_2003/17260_home_static.pt, Away -> static_game_tensors_redo/season_2003/17260_away_static.pt\n",
      "Saved static tensors for game 16596 in season 2003: Home -> static_game_tensors_redo/season_2003/16596_home_static.pt, Away -> static_game_tensors_redo/season_2003/16596_away_static.pt\n",
      "Saved static tensors for game 15509 in season 2003: Home -> static_game_tensors_redo/season_2003/15509_home_static.pt, Away -> static_game_tensors_redo/season_2003/15509_away_static.pt\n",
      "Saved static tensors for game 16419 in season 2003: Home -> static_game_tensors_redo/season_2003/16419_home_static.pt, Away -> static_game_tensors_redo/season_2003/16419_away_static.pt\n",
      "Saved static tensors for game 17537 in season 2003: Home -> static_game_tensors_redo/season_2003/17537_home_static.pt, Away -> static_game_tensors_redo/season_2003/17537_away_static.pt\n",
      "Saved static tensors for game 16965 in season 2003: Home -> static_game_tensors_redo/season_2003/16965_home_static.pt, Away -> static_game_tensors_redo/season_2003/16965_away_static.pt\n",
      "Saved static tensors for game 17066 in season 2003: Home -> static_game_tensors_redo/season_2003/17066_home_static.pt, Away -> static_game_tensors_redo/season_2003/17066_away_static.pt\n",
      "Saved static tensors for game 15510 in season 2003: Home -> static_game_tensors_redo/season_2003/15510_home_static.pt, Away -> static_game_tensors_redo/season_2003/15510_away_static.pt\n",
      "Saved static tensors for game 17539 in season 2003: Home -> static_game_tensors_redo/season_2003/17539_home_static.pt, Away -> static_game_tensors_redo/season_2003/17539_away_static.pt\n",
      "Saved static tensors for game 17538 in season 2003: Home -> static_game_tensors_redo/season_2003/17538_home_static.pt, Away -> static_game_tensors_redo/season_2003/17538_away_static.pt\n",
      "Saved static tensors for game 16597 in season 2003: Home -> static_game_tensors_redo/season_2003/16597_home_static.pt, Away -> static_game_tensors_redo/season_2003/16597_away_static.pt\n",
      "Saved static tensors for game 16421 in season 2003: Home -> static_game_tensors_redo/season_2003/16421_home_static.pt, Away -> static_game_tensors_redo/season_2003/16421_away_static.pt\n",
      "Saved static tensors for game 17361 in season 2003: Home -> static_game_tensors_redo/season_2003/17361_home_static.pt, Away -> static_game_tensors_redo/season_2003/17361_away_static.pt\n",
      "Saved static tensors for game 16295 in season 2003: Home -> static_game_tensors_redo/season_2003/16295_home_static.pt, Away -> static_game_tensors_redo/season_2003/16295_away_static.pt\n",
      "Saved static tensors for game 17262 in season 2003: Home -> static_game_tensors_redo/season_2003/17262_home_static.pt, Away -> static_game_tensors_redo/season_2003/17262_away_static.pt\n",
      "Saved static tensors for game 17261 in season 2003: Home -> static_game_tensors_redo/season_2003/17261_home_static.pt, Away -> static_game_tensors_redo/season_2003/17261_away_static.pt\n",
      "Saved static tensors for game 16420 in season 2003: Home -> static_game_tensors_redo/season_2003/16420_home_static.pt, Away -> static_game_tensors_redo/season_2003/16420_away_static.pt\n",
      "Saved static tensors for game 16296 in season 2003: Home -> static_game_tensors_redo/season_2003/16296_home_static.pt, Away -> static_game_tensors_redo/season_2003/16296_away_static.pt\n",
      "Saved static tensors for game 17540 in season 2003: Home -> static_game_tensors_redo/season_2003/17540_home_static.pt, Away -> static_game_tensors_redo/season_2003/17540_away_static.pt\n",
      "Saved static tensors for game 17362 in season 2003: Home -> static_game_tensors_redo/season_2003/17362_home_static.pt, Away -> static_game_tensors_redo/season_2003/17362_away_static.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1537/2999537695.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m# Loop through all games and save tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgames_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0msave_static_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1537/2999537695.py\u001b[0m in \u001b[0;36msave_static_tensors\u001b[0;34m(game_row)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Process home and away teams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mhome_static_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_team_static\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"home\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0maway_static_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_team_static\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"away\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1537/2999537695.py\u001b[0m in \u001b[0;36mprocess_team_static\u001b[0;34m(game_row, team_prefix)\u001b[0m\n\u001b[1;32m     76\u001b[0m         }\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplayer_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"player_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_or_lookup_player_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"player_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mplayer_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mplayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1537/2999537695.py\u001b[0m in \u001b[0;36mfetch_or_lookup_player_stats\u001b[0;34m(player_id)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mplayer_bio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPLAYER_BIO_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplayer_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplayer_bio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"player_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mplayer_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_bio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer_bio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"player_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplayer_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplayer_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3377\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3379\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterleaved_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36minterleaved_dtype\u001b[0;34m(dtypes)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mfind_common_type\u001b[0;34m(types)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[0;31m# None, type, _SupportsDtype, str, Tuple[Any, int], Tuple[Any, Union[int,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m     \u001b[0;31m# Sequence[int]]], List[Any], _DtypeDict, Tuple[Any, Any]]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36mfind_common_type\u001b[0;34m(array_types, scalar_types)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0mscalar_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscalar_types\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m     \u001b[0mmaxa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_can_coerce_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0mmaxsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_can_coerce_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36m_can_coerce_all\u001b[0;34m(dtypelist, start)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mthisind\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0m__len_test_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mnewdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__test_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthisind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mnumcoerce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypelist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnewdtype\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumcoerce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnewdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mthisind\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0m__len_test_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mnewdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__test_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthisind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mnumcoerce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypelist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnewdtype\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumcoerce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnewdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Processing and Saving Static Tensors for All Games in the Dataset\n",
    "# -----------------------------------------------------------------\n",
    "# This section handles the creation of static tensors for every game in the dataset.\n",
    "# Static tensors represent normalized, game-independent features for each team's players,\n",
    "# such as player stats (minutes, offensive/defensive ratings, usage), and physical attributes\n",
    "# (height, weight). These tensors are saved for each game and organized into season-specific folders.\n",
    "#\n",
    "# Workflow:\n",
    "# 1. **Player Bio Cache**:\n",
    "#    - A CSV file (`playerBio.csv`) is used to store height and weight data for players to minimize\n",
    "#      redundant API calls. Default values are provided for players not found in the cache.\n",
    "#\n",
    "# 2. **Feature Normalization**:\n",
    "#    - Player statistics and physical attributes are normalized using `MinMaxScaler`.\n",
    "#    - Ensures that all numeric features are scaled consistently for better input to the model.\n",
    "#\n",
    "# 3. **Tensor Construction**:\n",
    "#    - Static features for each team (home and away) are converted into PyTorch tensors.\n",
    "#    - Tensors are padded to ensure 12 players per team, maintaining a consistent shape.\n",
    "#\n",
    "# 4. **Game Organization**:\n",
    "#    - Processed tensors are saved in season-specific directories within `static_game_tensors`.\n",
    "#    - Each tensor file is named using the game ID and team (e.g., `gameID_home_static.pt`).\n",
    "#\n",
    "# 5. **Validation and Error Handling**:\n",
    "#    - Games with missing or invalid data (e.g., missing player IDs or stats) are skipped with a warning.\n",
    "#    - Errors during processing are caught and logged without interrupting the overall loop.\n",
    "#\n",
    "# 6. **Dataset Loading and Iteration**:\n",
    "#    - The expanded dataset (`expanded_games_2003_2023.csv`) is loaded and iterated row by row.\n",
    "#    - Static tensors for each game are processed and saved in a batch manner.\n",
    "#\n",
    "# Output:\n",
    "# - Static tensors are stored in `static_game_tensors` organized by season.\n",
    "# - These tensors will later be combined with dynamic encodings (e.g., `playerID`, `position`, `teamID`)\n",
    "#   at runtime during training or testing of the deep learning model.\n",
    "#\n",
    "# Notes:\n",
    "# - Tensors are crucial for representing game data in a format suitable for transformer networks.\n",
    "# - This preprocessing step is designed for efficient retrieval and consistent data structure.\n",
    "\n",
    "PLAYER_BIO_FILE = \"playerBio.csv\"\n",
    "\n",
    "# Directory for saving static tensors\n",
    "TENSOR_DIR = \"static_game_tensors_redo\"\n",
    "os.makedirs(TENSOR_DIR, exist_ok=True)\n",
    "\n",
    "# Create the player bio file if it doesn't exist\n",
    "if not os.path.exists(PLAYER_BIO_FILE):\n",
    "    pd.DataFrame(columns=[\"player_id\", \"height\", \"weight\"]).to_csv(PLAYER_BIO_FILE, index=False)\n",
    "\n",
    "def fetch_or_lookup_player_stats(player_id):\n",
    "    \"\"\"\n",
    "    Fetch the player's height and weight from the lookup file or API.\n",
    "    \"\"\"\n",
    "    player_bio = pd.read_csv(PLAYER_BIO_FILE)\n",
    "    if player_id in player_bio[\"player_id\"].values:\n",
    "        player_row = player_bio[player_bio[\"player_id\"] == player_id].iloc[0]\n",
    "        return {\"height\": player_row[\"height\"], \"weight\": player_row[\"weight\"]}\n",
    "    else:\n",
    "        return {\"height\": 72, \"weight\": 200}  # Default values\n",
    "\n",
    "def process_team_static(game_row, team_prefix):\n",
    "    \"\"\"\n",
    "    Process a team's static features for saving.\n",
    "    \"\"\"\n",
    "    players = []\n",
    "    for i in range(1, 13):\n",
    "        player_id = game_row[f\"{team_prefix}_player_{i}_id\"]\n",
    "        player_data = {\n",
    "            \"player_id\": int(player_id) if not pd.isna(player_id) else None,\n",
    "            \"minutes\": game_row[f\"{team_prefix}_player_{i}_minutes\"],\n",
    "            \"off_rating\": game_row[f\"{team_prefix}_player_{i}_off_rating\"],\n",
    "            \"def_rating\": game_row[f\"{team_prefix}_player_{i}_def_rating\"],\n",
    "            \"usage\": game_row[f\"{team_prefix}_player_{i}_usage\"],\n",
    "        }\n",
    "        if player_data[\"player_id\"] is not None:\n",
    "            stats = fetch_or_lookup_player_stats(player_data[\"player_id\"])\n",
    "            player_data.update(stats)\n",
    "        players.append(player_data)\n",
    "\n",
    "    # Normalize static features\n",
    "    numeric_features = [\"minutes\", \"off_rating\", \"def_rating\", \"usage\", \"height\", \"weight\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    numeric_data = [[player[f] for f in numeric_features] for player in players if player[\"player_id\"] is not None]\n",
    "    if len(numeric_data) > 0:\n",
    "        scaler.fit(numeric_data)\n",
    "        normalized_data = scaler.transform(numeric_data)\n",
    "    else:\n",
    "        normalized_data = []\n",
    "\n",
    "    team_tensor = []\n",
    "    for i, player in enumerate(players):\n",
    "        if player[\"player_id\"] is None:\n",
    "            continue\n",
    "        numeric_values = [player[f] if f in player and player[f] is not None else 0 for f in numeric_features]\n",
    "        normalized_features = scaler.transform([numeric_values])[0] if len(numeric_data) > 0 else [0] * len(numeric_features)\n",
    "        static_tensor = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "        team_tensor.append(static_tensor)\n",
    "\n",
    "    # Sort players by playtime (minutes played) in descending order\n",
    "    team_tensor = [tensor for _, tensor in sorted(zip(numeric_data, team_tensor), key=lambda x: x[0][0], reverse=True)]\n",
    "\n",
    "    # Pad to ensure 12 players\n",
    "    while len(team_tensor) < 12:\n",
    "        team_tensor.append(torch.zeros_like(team_tensor[0]))\n",
    "\n",
    "    return torch.stack(team_tensor)\n",
    "\n",
    "def save_static_tensors(game_row):\n",
    "    \"\"\"\n",
    "    Save home and away static tensors for a game in season-specific folders.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract season and game ID\n",
    "        season = game_row[\"season\"]\n",
    "        game_id = game_row[\"game_id\"]\n",
    "\n",
    "        # Skip rows with invalid critical values\n",
    "        if pd.isna(season) or pd.isna(game_id) or pd.isna(game_row[\"home_team_id\"]) or pd.isna(game_row[\"visitor_team_id\"]):\n",
    "            print(f\"Skipping invalid game data: Game ID {game_id}\")\n",
    "            return\n",
    "\n",
    "        # Process home and away teams\n",
    "        home_static_tensor = process_team_static(game_row, \"home\")\n",
    "        away_static_tensor = process_team_static(game_row, \"away\")\n",
    "\n",
    "        # Save tensors\n",
    "        season_dir = os.path.join(TENSOR_DIR, f\"season_{season}\")\n",
    "        os.makedirs(season_dir, exist_ok=True)\n",
    "        home_path = os.path.join(season_dir, f\"{game_id}_home_static.pt\")\n",
    "        away_path = os.path.join(season_dir, f\"{game_id}_away_static.pt\")\n",
    "        torch.save(home_static_tensor, home_path)\n",
    "        torch.save(away_static_tensor, away_path)\n",
    "        print(f\"Saved static tensors for game {game_id} in season {season}: Home -> {home_path}, Away -> {away_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing game {game_row['game_id'] if 'game_id' in game_row else 'unknown'}: {e}\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"expanded_games_2003_2023.csv\"\n",
    "try:\n",
    "    games_df = pd.read_csv(dataset_path)\n",
    "    print(f\"Dataset '{dataset_path}' loaded successfully. Number of rows: {len(games_df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{dataset_path}' not found.\")\n",
    "    raise\n",
    "\n",
    "# Loop through all games and save tensors\n",
    "for _, game_row in games_df.iterrows():\n",
    "    save_static_tensors(game_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another issue that popped up during the creation and testing of our model had to deal with the size of playerID numbers in newer seasons (they grew huge).\n",
    "#### We overcome that here through normalization in the PlayerBio.csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Accomplishments\n",
    "\n",
    "- Successfully retrieved and processed **~27,000 NBA games** spanning two decades (2003–2023).\n",
    "- Built a comprehensive dataset incorporating detailed player and game statistics, including **player usage**, **minutes played**, and **team compositions**.\n",
    "- Overcame challenges such as missing data, API rate limits, and long processing times using **incremental saving** and **parallelized API calls**.\n",
    "- Created normalized **static tensors** for each game, containing player-level metrics (e.g., offensive/defensive ratings, height, and weight) and structured them for efficient model integration.\n",
    "- Established a flexible framework that supports the addition of more detailed player statistics (e.g., height/weight updates) through quick API lookups if needed.\n",
    "\n",
    "This dataset now serves as a robust foundation for training the transformer-based deep learning model, enabling advanced analysis and predictions in subsequent sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **II. Model Creation**\n",
    "\n",
    "### Overview\n",
    "This section focuses on building a transformer-based deep learning model to predict NBA game outcomes. The model will analyze static player features and dynamically learned embeddings to generate predictions.\n",
    "\n",
    "### Goals\n",
    "1. **Model Architecture**:\n",
    "   - Implement a transformer network using **PyTorch**.\n",
    "   - Use multi-head attention mechanisms to analyze player-to-player and team-to-team relationships.\n",
    "   - Experiment with architectures that include residual connections to enhance model depth and stability.\n",
    "\n",
    "2. **Input and Output Design**:\n",
    "   - **Inputs**:\n",
    "     - Static tensors for each team, including player statistics normalized per game.\n",
    "     - Dynamically learned embeddings for PlayerID, PositionID, TeamID, and Season, added at runtime.\n",
    "   - **Outputs**:\n",
    "     - Predict the final scores for the home and away teams.\n",
    "\n",
    "3. **Model Training**:\n",
    "   - Train the model chronologically, using data from past games to predict future ones.\n",
    "   - Define the training loop with appropriate loss functions and optimizers.\n",
    "   - Split data into training, validation, and test sets based on game chronology for temporal consistency.\n",
    "\n",
    "### Implementation Steps\n",
    "1. **Set Up Dynamic Embeddings**:\n",
    "   - Initialize embeddings for PlayerID, PositionID, TeamID, and Season, which will be added dynamically to the static tensors at runtime.\n",
    "\n",
    "2. **Combine Static and Dynamic Features**:\n",
    "   - Design a process to concatenate static and dynamic features for each player token during training and inference.\n",
    "\n",
    "3. **Define the Transformer Architecture**:\n",
    "   - Specify input dimensions, number of attention heads, and transformer layers.\n",
    "   - Experiment with designs, including multi-head attention blocks and fully connected layers.\n",
    "\n",
    "4. **Configure the Training Pipeline**:\n",
    "   - Choose a regression-based loss function (e.g., Mean Squared Error) and an optimizer (e.g., Adam).\n",
    "   - Set hyperparameters such as learning rate, batch size, and number of epochs.\n",
    "\n",
    "5. **Initial Testing**:\n",
    "   - Train the model on a subset of the data (e.g., a single season) to validate functionality and debug issues.\n",
    "   - Evaluate performance metrics (e.g., MSE, RMSE) and refine the architecture.\n",
    "\n",
    "6. **Scaling and Tuning**:\n",
    "   - Train on the full dataset after initial testing.\n",
    "   - Perform hyperparameter tuning to optimize model performance.\n",
    "\n",
    "---\n",
    "\n",
    "This section will document the detailed process of creating and implementing the model, highlighting the reasoning behind architectural and design decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Tokens Shape: torch.Size([12, 48])\n",
      "Away Tokens Shape: torch.Size([12, 48])\n",
      "Home Token 0:\n",
      "tensor([ 0.2969,  1.1050, -1.0692, -0.1681,  1.6968,  0.4612,  1.1499,  1.1575,\n",
      "        -0.1793,  1.6901, -0.6646,  2.1300, -1.1579,  1.1120, -0.6387, -0.3155,\n",
      "         1.2548, -1.2322,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  1.0000,  0.9069,  0.7266,  0.7092,  0.0000,  0.1786],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 1:\n",
      "tensor([ 1.2598, -0.2457,  1.0140,  0.0974, -1.6120, -0.3490,  0.3838,  0.2361,\n",
      "         1.4533, -0.2876, -0.3169, -0.0651, -0.4180, -1.2510, -0.5809, -0.9387,\n",
      "        -1.0161, -0.7057,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.9651,  0.9735,  0.7326,  0.9078,  0.2500,  0.0357],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 2:\n",
      "tensor([-1.4961,  2.6531,  0.6869,  2.0961,  0.0996, -0.0342,  1.1441, -0.3430,\n",
      "        -0.5647, -0.5495,  0.0894,  0.1859, -0.3779,  1.2227, -2.0337,  0.9966,\n",
      "        -0.6537,  0.0312,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.9272,  0.9029,  0.8089,  0.4043,  0.5833,  0.3571],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 3:\n",
      "tensor([ 0.5631, -0.2239,  1.0007, -1.1863, -0.6350,  0.7888, -1.0390,  0.9871,\n",
      "         0.4401,  1.8140,  1.8030,  1.1443, -0.3870, -0.2559,  0.6873,  0.1948,\n",
      "         0.5213, -1.4378,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.8579,  0.9133,  0.7515,  1.0000,  1.0000,  1.0000],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 4:\n",
      "tensor([ 0.0681, -2.0446, -0.4722,  1.9387, -0.2688, -1.1060,  0.6126,  0.7269,\n",
      "         1.0441, -0.1249,  1.8567,  1.5298,  0.1195,  0.3089,  1.0767, -1.4096,\n",
      "        -0.7822, -0.5584,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.7775,  1.0000,  0.7232,  0.6986,  0.6667,  0.5286],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 5:\n",
      "tensor([-0.5825, -0.3587,  0.1694,  0.3978, -0.9047, -0.8533,  0.5576,  0.6660,\n",
      "        -1.9504, -0.3031, -0.4657,  0.8781,  0.1057,  0.0151, -0.1227, -0.8166,\n",
      "         0.9334, -0.2785,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.5572,  0.7841,  0.8380,  0.6950,  0.5000,  0.2857],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 6:\n",
      "tensor([ 1.5605, -0.6834,  0.3629,  0.5140, -0.7954,  0.5265, -0.7497, -0.4441,\n",
      "         1.0529, -0.3321,  1.2990, -0.6105, -0.8822,  0.1180, -0.2905, -0.5359,\n",
      "         0.7196,  0.0879,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.5362,  0.7841,  0.8569,  0.2234,  0.7500,  0.4286],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 7:\n",
      "tensor([-0.5591,  2.6503,  0.9994,  0.3167, -1.9974, -0.7663,  0.4177,  0.4022,\n",
      "        -0.7029, -1.4196, -1.0038, -0.1682,  0.4945,  0.5645, -2.1582, -0.1414,\n",
      "        -1.4938, -0.1226,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.3753,  0.7472,  0.9751,  0.6879,  0.4167,  0.2143],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 8:\n",
      "tensor([-2.1098,  1.3057, -0.2771,  0.0419,  1.3444,  0.0999, -0.4683, -0.3337,\n",
      "        -1.0262, -0.4385,  0.4808,  1.4276, -0.3824,  0.6138, -0.6371,  1.1530,\n",
      "        -0.1690, -1.6564,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.2413,  0.5490,  1.0000,  0.8865,  0.0000,  0.0000],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 9:\n",
      "tensor([ 0.5049, -0.7357,  1.2202,  1.5230, -0.9355, -0.5932, -1.3653, -1.8008,\n",
      "         0.4010, -0.4319,  0.1998,  1.7117, -0.4628, -0.2978, -1.0971,  1.7987,\n",
      "        -0.6348, -0.4035,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.1877,  0.3652,  0.6590,  0.8191,  0.5833,  0.3571],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 10:\n",
      "tensor([-0.8384, -0.2606,  0.6543, -1.5231, -0.1673,  2.1797, -1.1794, -0.6890,\n",
      "        -0.1398, -0.2995,  1.2708,  1.2542, -2.3074, -0.5036, -2.2598,  0.7623,\n",
      "        -0.5041,  0.0825,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.0000,  0.0000,  0.0000,  0.0000,  0.4167,  0.1929],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Home Token 11:\n",
      "tensor([-1.2965,  0.3300, -0.1403,  0.0343, -0.0914,  0.0324, -0.9926, -1.2096,\n",
      "         0.5547,  1.6155, -1.5060, -0.4912, -0.2175, -0.8703, -0.7999,  0.1904,\n",
      "        -1.0941,  1.0734,  1.1627, -0.0210,  0.8587,  0.1787, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.0000,  0.0000,  0.0000,  0.0000,  0.7500,  0.4857],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 0:\n",
      "tensor([-0.0461,  0.4375, -1.3815,  0.6032, -0.9541, -0.4988,  0.7997, -1.2194,\n",
      "        -1.2842, -0.8082,  0.4062,  0.5566, -0.8200,  0.0125,  1.0889, -0.0113,\n",
      "        -0.4541, -0.7328, -1.8580,  0.1057, -0.6828, -0.4903, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  1.0000,  0.6000,  0.8216,  0.7818,  0.6842,  0.6907],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 1:\n",
      "tensor([ 0.4653,  1.0015,  2.4222,  1.0615, -0.1371,  0.5897, -0.7063,  0.2992,\n",
      "         1.2433, -1.8571,  0.3655, -0.3314, -1.2291, -0.6915,  1.1154, -1.4040,\n",
      "        -1.2840,  0.1651, -1.8580,  0.1057, -0.6828, -0.4903, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.9937,  0.6913,  0.8501,  0.4052,  0.5263,  0.6907],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 2:\n",
      "tensor([-0.3118, -0.7135,  0.1960,  0.9039, -0.6136, -0.8754, -1.3947,  1.3271,\n",
      "        -0.6736, -1.3749, -0.1837, -0.0362, -1.3694,  0.6307,  1.2676,  0.3199,\n",
      "        -0.0525,  0.1625,  1.1627, -0.0210,  0.8587,  0.1787, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.9886,  0.9780,  0.6774,  0.3974,  0.5263,  0.5876],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 3:\n",
      "tensor([-1.9166e+00,  1.8721e-01,  6.5366e-01, -7.4959e-01,  8.2574e-01,\n",
      "        -1.4072e+00, -5.6939e-01,  2.6264e-03, -5.2301e-01,  2.1671e+00,\n",
      "         2.7900e+00,  2.4556e-01, -4.5112e-01, -8.5370e-01, -6.0167e-01,\n",
      "        -1.9559e+00,  1.6274e+00,  4.7898e-01,  1.1627e+00, -2.1025e-02,\n",
      "         8.5871e-01,  1.7874e-01, -1.7088e+00, -3.2274e-01, -1.5775e+00,\n",
      "        -1.1946e+00, -8.2410e-01,  8.5059e-01,  1.3286e-01, -1.4886e+00,\n",
      "        -9.8607e-02,  2.3293e+00, -1.9904e+00,  7.8758e-03, -3.4183e-01,\n",
      "        -1.3153e+00, -1.6089e+00, -1.7886e-01, -1.7242e-01,  7.9888e-01,\n",
      "         1.3324e+00,  4.0341e-01,  8.5608e-01,  7.4016e-01,  7.8748e-01,\n",
      "         4.2857e-01,  4.2105e-01,  4.8454e-01], grad_fn=<SelectBackward0>)\n",
      "Away Token 4:\n",
      "tensor([-8.5020e-01,  1.9425e+00, -1.8608e-02,  2.2792e+00,  1.2716e+00,\n",
      "         4.6047e-01,  5.0958e-01, -1.9294e+00,  1.9372e-01,  1.2695e+00,\n",
      "        -8.7860e-01, -1.6897e+00, -9.5353e-04,  7.6495e-01, -8.2423e-01,\n",
      "        -2.8087e+00,  2.3771e-01,  1.9829e+00,  1.1627e+00, -2.1025e-02,\n",
      "         8.5871e-01,  1.7874e-01, -1.7088e+00, -3.2274e-01, -1.5775e+00,\n",
      "        -1.1946e+00, -8.2410e-01,  8.5059e-01,  1.3286e-01, -1.4886e+00,\n",
      "        -9.8607e-02,  2.3293e+00, -1.9904e+00,  7.8758e-03, -3.4183e-01,\n",
      "        -1.3153e+00, -1.6089e+00, -1.7886e-01, -1.7242e-01,  7.9888e-01,\n",
      "         1.3324e+00,  4.0341e-01,  8.2239e-01,  5.8583e-01,  9.8482e-01,\n",
      "         4.5195e-01,  2.1053e-01,  0.0000e+00], grad_fn=<SelectBackward0>)\n",
      "Away Token 5:\n",
      "tensor([-1.2736,  0.5552,  0.6210, -1.7306, -0.0764,  0.0566, -1.0609,  0.5707,\n",
      "         0.0834,  0.3801, -1.0881,  0.9739,  0.1713,  0.0682,  1.0860, -0.0597,\n",
      "         1.8775,  0.8967,  1.1627, -0.0210,  0.8587,  0.1787, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.8035,  0.8976,  0.6110,  0.3117,  0.1579,  0.1134],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 6:\n",
      "tensor([ 1.0178,  0.3221, -0.4453,  0.4339, -0.5970,  1.0938, -0.2421,  0.4277,\n",
      "         0.0508, -0.2681, -1.0915, -0.9709, -0.0124, -0.4537, -0.8835,  0.5856,\n",
      "         0.7367,  0.8202,  1.1627, -0.0210,  0.8587,  0.1787, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.4112,  1.0000,  0.3264,  0.3273,  0.0000,  0.0412],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 7:\n",
      "tensor([ 0.4946,  1.5205,  0.8620, -0.4612, -0.6474, -0.3027, -0.3824,  0.2000,\n",
      "        -0.4560, -1.6296, -0.6593,  0.3422, -1.6038, -0.9770,  0.4192, -1.5591,\n",
      "         1.3934,  0.0904,  1.1627, -0.0210,  0.8587,  0.1787, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.3427,  0.0000,  1.0000,  0.0000,  0.4737,  0.8454],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 8:\n",
      "tensor([ 0.5808, -1.6666, -0.2354, -0.0956, -1.7370,  1.2642,  2.1058, -0.6061,\n",
      "        -1.3966, -0.5180, -1.1457, -0.2021,  0.3458, -0.0090,  0.0212,  1.0179,\n",
      "         0.0678,  0.2931, -1.8580,  0.1057, -0.6828, -0.4903, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.3084,  0.9906,  0.5427,  0.1844,  0.4737,  0.5876],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 9:\n",
      "tensor([ 0.0619, -0.3923, -0.9614, -0.4144, -0.8137, -0.2350, -1.5143, -0.4313,\n",
      "         1.3234,  0.4497, -0.2211,  0.4303,  1.2579, -0.0820, -0.3821, -1.5604,\n",
      "        -1.4086,  0.0293,  1.1627, -0.0210,  0.8587,  0.1787, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.0343,  0.7118,  0.3529,  1.0000,  0.4211,  0.3299],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 10:\n",
      "tensor([ 0.7781, -0.8101,  1.3990, -0.9015,  0.7862,  0.3407, -0.2248,  0.6255,\n",
      "        -2.0370, -0.5026,  1.6396,  1.0072,  0.0810,  2.0866, -1.0363,  1.4218,\n",
      "        -2.3638, -1.1147,  1.1627, -0.0210,  0.8587,  0.1787, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.0000,  0.6724,  0.0000,  0.4364,  1.0000,  1.0000],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Away Token 11:\n",
      "tensor([ 0.5371,  1.1864, -1.8935, -0.3982,  2.8506, -0.5173,  0.0999, -1.0336,\n",
      "         1.9776,  0.3177,  0.8478, -0.8023,  0.7078, -1.5666, -0.5956,  1.5853,\n",
      "        -1.0983, -0.0760,  1.1627, -0.0210,  0.8587,  0.1787, -1.7088, -0.3227,\n",
      "        -1.5775, -1.1946, -0.8241,  0.8506,  0.1329, -1.4886, -0.0986,  2.3293,\n",
      "        -1.9904,  0.0079, -0.3418, -1.3153, -1.6089, -0.1789, -0.1724,  0.7989,\n",
      "         1.3324,  0.4034,  0.0000,  0.8693,  0.0000,  0.2052,  0.3684,  0.2268],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Transformer Input Token Creation for NBA Prediction Model\n",
    "# -----------------------------------------------------------\n",
    "# This section focuses on creating player tokens, which serve as input for a transformer-based deep learning model.\n",
    "# The tokens combine dynamic embeddings (e.g., player IDs, positions, team relationships) with static tensors\n",
    "# (game-independent player features like normalized stats and physical attributes).\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "STATIC_TENSOR_DIR = \"static_game_tensors_redo\"\n",
    "\n",
    "# Embedding dimensions\n",
    "E_player = 18  # PlayerID embedding size\n",
    "E_position = 4\n",
    "E_team = 8\n",
    "E_season = 4\n",
    "\n",
    "# Max ranges for embedding indices\n",
    "max_normalized_player_id = 2500  # Using normalized PlayerIDs\n",
    "max_team_id = 32  # Total teams (incl. Supersonics)\n",
    "max_position_id = 3  # C, F, G, None -> 0, 1, 2, 3\n",
    "max_season_id = 22  # Seasons 2003 to 2023 -> 0 to 20\n",
    "\n",
    "# Initialize embeddings\n",
    "player_embedding = nn.Embedding(max_normalized_player_id + 1, E_player)\n",
    "position_embedding = nn.Embedding(max_position_id + 1, E_position)\n",
    "team_embedding = nn.Embedding(max_team_id + 1, E_team)\n",
    "season_embedding = nn.Embedding(max_season_id + 1, E_season)\n",
    "\n",
    "# Load the player ID mapping from playerBio.csv\n",
    "player_bio_df = pd.read_csv(\"playerBio.csv\").set_index(\"player_id\")\n",
    "player_id_mapping = player_bio_df[\"normalized_id\"].to_dict()\n",
    "\n",
    "def load_static_tensor(game_id, team_type, season):\n",
    "    \"\"\"\n",
    "    Load the static tensor for a team (home/away) in a specific game.\n",
    "    \"\"\"\n",
    "    tensor_path = os.path.join(STATIC_TENSOR_DIR, f\"season_{season}\", f\"{game_id}_{team_type}_static.pt\")\n",
    "    if not os.path.exists(tensor_path):\n",
    "        raise FileNotFoundError(f\"Static tensor not found: {tensor_path}\")\n",
    "    return torch.load(tensor_path)\n",
    "\n",
    "\n",
    "def create_player_token(player_id, position_id, team_id_for, team_id_against, season_id, static_tensor, player_id_mapping):\n",
    "    \"\"\"\n",
    "    Concatenate dynamic embeddings with static features to create a full player token.\n",
    "    Replaces NaN height and weight in static_tensor with league averages (6'7\", 220 lbs).\n",
    "    \"\"\"\n",
    "    # Map raw player ID to normalized ID\n",
    "    normalized_player_id = player_id_mapping.get(player_id, 0)  # Default to 0 for invalid IDs\n",
    "\n",
    "    try:\n",
    "        # Replace NaN height and weight in static_tensor with league averages\n",
    "        static_tensor = torch.nan_to_num(static_tensor, nan=torch.tensor(79.0 if i == 0 else 220.0, dtype=torch.float32)) \n",
    "\n",
    "        # Generate dynamic embeddings\n",
    "        player_id_tensor = player_embedding(torch.tensor(normalized_player_id, dtype=torch.long))\n",
    "        position_tensor = position_embedding(torch.tensor(position_id if position_id is not None else 3, dtype=torch.long))\n",
    "        team_for_tensor = team_embedding(torch.tensor(team_id_for, dtype=torch.long))\n",
    "        team_against_tensor = team_embedding(torch.tensor(team_id_against, dtype=torch.long))\n",
    "        season_tensor = season_embedding(torch.tensor(season_id, dtype=torch.long))\n",
    "\n",
    "        # Validate all tensors for NaN\n",
    "        for tensor, name in [\n",
    "            (player_id_tensor, \"player_id_tensor\"),\n",
    "            (position_tensor, \"position_tensor\"),\n",
    "            (team_for_tensor, \"team_for_tensor\"),\n",
    "            (team_against_tensor, \"team_against_tensor\"),\n",
    "            (season_tensor, \"season_tensor\"),\n",
    "            (static_tensor, \"static_tensor\"),\n",
    "        ]:\n",
    "            assert not torch.isnan(tensor).any(), f\"NaN detected in {name}\"\n",
    "\n",
    "        # Concatenate dynamic and static features\n",
    "        token = torch.cat([\n",
    "            player_id_tensor,\n",
    "            position_tensor,\n",
    "            team_for_tensor,\n",
    "            team_against_tensor,\n",
    "            season_tensor,\n",
    "            static_tensor\n",
    "        ])\n",
    "\n",
    "        # Validate the final token\n",
    "        assert not torch.isnan(token).any(), \"NaN detected in player token\"\n",
    "\n",
    "        return token\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in token creation for player_id {player_id} (normalized ID: {normalized_player_id}): {e}\")\n",
    "        # Return a zeroed-out token as a fallback\n",
    "        return torch.zeros(\n",
    "            E_player + E_position + E_team * 2 + E_season + static_tensor.shape[0]\n",
    "        )\n",
    "\n",
    "\n",
    "def create_game_tokens(game_id, season, home_team_id, away_team_id, games_df, player_id_mapping):\n",
    "    \"\"\"\n",
    "    Generate tokens for all players in a game (home and away).\n",
    "    \"\"\"\n",
    "    # Mapping for position to IDs\n",
    "    position_mapping = {\"C\": 0, \"F\": 1, \"G\": 2, None: 3}\n",
    "\n",
    "    # Load static tensors\n",
    "    home_static_tensor = load_static_tensor(game_id, \"home\", season)\n",
    "    away_static_tensor = load_static_tensor(game_id, \"away\", season)\n",
    "\n",
    "    # Extract player data dynamically from the dataframe\n",
    "    home_players = [\n",
    "        {\"player_id\": int(games_df[f\"home_player_{i}_id\"]) if not pd.isna(games_df[f\"home_player_{i}_id\"]) else None,\n",
    "         \"position_id\": position_mapping.get(games_df[f\"home_player_{i}_position\"], 3)}\n",
    "        for i in range(1, 13)\n",
    "    ]\n",
    "    away_players = [\n",
    "        {\"player_id\": int(games_df[f\"away_player_{i}_id\"]) if not pd.isna(games_df[f\"away_player_{i}_id\"]) else None,\n",
    "         \"position_id\": position_mapping.get(games_df[f\"away_player_{i}_position\"], 3)}\n",
    "        for i in range(1, 13)\n",
    "    ]\n",
    "\n",
    "    # Create player tokens for home team\n",
    "    home_tokens = []\n",
    "    for i, player in enumerate(home_players):\n",
    "        if player[\"player_id\"] is None:\n",
    "            continue\n",
    "        player_token = create_player_token(\n",
    "            player_id=player[\"player_id\"],\n",
    "            position_id=player[\"position_id\"],\n",
    "            team_id_for=home_team_id,\n",
    "            team_id_against=away_team_id,\n",
    "            season_id=season - 2003,  # Normalize season to 0-20\n",
    "            static_tensor=home_static_tensor[i],\n",
    "            player_id_mapping=player_id_mapping\n",
    "        )\n",
    "        home_tokens.append(player_token)\n",
    "\n",
    "    # Create player tokens for away team\n",
    "    away_tokens = []\n",
    "    for i, player in enumerate(away_players):\n",
    "        if player[\"player_id\"] is None:\n",
    "            continue\n",
    "        player_token = create_player_token(\n",
    "            player_id=player[\"player_id\"],\n",
    "            position_id=player[\"position_id\"],\n",
    "            team_id_for=away_team_id,\n",
    "            team_id_against=home_team_id,\n",
    "            season_id=season - 2003,  # Normalize season to 0-20\n",
    "            static_tensor=away_static_tensor[i],\n",
    "            player_id_mapping=player_id_mapping\n",
    "        )\n",
    "        away_tokens.append(player_token)\n",
    "\n",
    "    # Ensure each team has exactly 12 tokens\n",
    "    while len(home_tokens) < 12:\n",
    "        home_tokens.append(torch.zeros_like(home_tokens[0]))\n",
    "    while len(away_tokens) < 12:\n",
    "        away_tokens.append(torch.zeros_like(away_tokens[0]))\n",
    "\n",
    "    # Stack tokens for both teams\n",
    "    home_tokens = torch.stack(home_tokens)\n",
    "    away_tokens = torch.stack(away_tokens)\n",
    "\n",
    "    # Validate final tokens\n",
    "    assert not torch.isnan(home_tokens).any(), \"NaN detected in final home tokens\"\n",
    "    assert not torch.isnan(away_tokens).any(), \"NaN detected in final away tokens\"\n",
    "\n",
    "    return home_tokens, away_tokens\n",
    "\n",
    "# Load the player ID mapping from playerBio.csv\n",
    "player_bio_df = pd.read_csv(\"playerBio.csv\").set_index(\"player_id\")\n",
    "player_id_mapping = player_bio_df[\"normalized_id\"].to_dict()\n",
    "\n",
    "# Example Usage\n",
    "game_id = 15486\n",
    "season = 2003\n",
    "home_team_id = 13  # Lakers\n",
    "away_team_id = 7  # Mavericks\n",
    "\n",
    "# Load games dataframe\n",
    "games_df = pd.read_csv(\"expanded_games_2003_2023.csv\").set_index(\"game_id\").loc[game_id]\n",
    "\n",
    "# Generate tokens\n",
    "home_tokens, away_tokens = create_game_tokens(game_id, season, home_team_id, away_team_id, games_df, player_id_mapping)\n",
    "\n",
    "# Print results\n",
    "print(f\"Home Tokens Shape: {home_tokens.shape}\")\n",
    "print(f\"Away Tokens Shape: {away_tokens.shape}\")\n",
    "for i in range(12):\n",
    "    print(f\"Home Token {i}:\\n{home_tokens[i]}\")\n",
    "for i in range(12):\n",
    "    print(f\"Away Token {i}:\\n{away_tokens[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of our 24x48 Tensor Transformer Network Inputs\n",
    "\n",
    "For each NBA game, we represent the **home team** and **away team** with two separate tensors, each with a shape of `12x48`. These tensors include both **static features** and **dynamic embeddings** for the top 12 players from each team. Here's a breakdown of the tensor structure:\n",
    "\n",
    "---\n",
    "\n",
    "#### **Per Team Tensor Dimensions**\n",
    "- **12 Rows**: Each row represents a player token, ordered by minutes played during the game.\n",
    "- **48 Columns**: Each column corresponds to a feature derived from either static or dynamic data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Feature Breakdown (48 Features per Player)**\n",
    "\n",
    "1. **Dynamic Embeddings (42 Features)**:\n",
    "   - **PlayerID Embedding (18 Features)**:\n",
    "     - A learned embedding representing the unique player.\n",
    "   - **PositionID Embedding (4 Features)**:\n",
    "     - A learned embedding representing the player's position (`C`, `F`, `G`, or `None`).\n",
    "   - **TeamID Embedding (16 Features)**:\n",
    "     - Two separate embeddings for:\n",
    "       1. The team the player is playing **for** (8 features).\n",
    "       2. The team the player is playing **against** (8 features).\n",
    "   - **Season Embedding (4 Features)**:\n",
    "     - A learned embedding representing the season the game took place in.\n",
    "\n",
    "2. **Static Features (6 Features)**:\n",
    "   - **Minutes Played** (normalized): The player's total minutes on the court.\n",
    "   - **Offensive Rating** (normalized): Player's offensive efficiency.\n",
    "   - **Defensive Rating** (normalized): Player's defensive efficiency.\n",
    "   - **Usage Percentage** (normalized): Player's involvement in the offense.\n",
    "   - **Height** (normalized): Player's height in inches.\n",
    "   - **Weight** (normalized): Player's weight in pounds.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Token Example**\n",
    "For a single game:\n",
    "- **Shape**: `[1, 48]`\n",
    "- **Example for Player 1**:\n",
    "  ```plaintext\n",
    "  tensor([PlayerID Embedding (18), \n",
    "          PositionID Embedding (4), \n",
    "          Team For Embedding (8), \n",
    "          Team Against Embedding (8), \n",
    "          Season Embedding (4), \n",
    "          Minutes Played (1), \n",
    "          Offensive Rating (1), \n",
    "          Defensive Rating (1), \n",
    "          Usage Percentage (1), \n",
    "          Height (1), \n",
    "          Weight (1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 1/10, Loss: 119347.3756\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 2/10, Loss: 11867.7079\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 3/10, Loss: 11704.0942\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 4/10, Loss: 11834.8847\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 5/10, Loss: 12010.7127\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 6/10, Loss: 11470.1634\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 7/10, Loss: 10307.1736\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 8/10, Loss: 10234.6080\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 9/10, Loss: 9980.3204\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 10/10, Loss: 10319.3499\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"enable_nested_tensor is True, but self.use_nested_tensor is False because\"\n",
    "        \" encoder_layer.self_attn.batch_first was not True\"\n",
    "    ),\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\"You are using `torch.load` with `weights_only=False`.*\",\n",
    "    category=FutureWarning\n",
    ")\n",
    "\n",
    "STATIC_TENSOR_DIR = \"static_game_tensors_redo\"\n",
    "\n",
    "# Dataset class for the 2003 season\n",
    "class NBA2003Dataset(Dataset):\n",
    "    def __init__(self, games_df):\n",
    "        self.games_df = games_df[games_df[\"season\"] == 2003]  # Filter for 2003 season\n",
    "        self.game_ids = self.games_df.index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.game_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        game_id = self.game_ids[idx]\n",
    "\n",
    "        try:\n",
    "            # Extract the row as a Series\n",
    "            game_row = self.games_df.loc[game_id]\n",
    "            if isinstance(game_row, pd.DataFrame):  # Handle duplicate game_id scenario\n",
    "                game_row = game_row.iloc[0]  # Take the first occurrence\n",
    "\n",
    "            # Ensure all scalar values\n",
    "            season = int(game_row[\"season\"])\n",
    "            home_team_id = int(game_row[\"home_team_id\"])\n",
    "            away_team_id = int(game_row[\"visitor_team_id\"])\n",
    "\n",
    "            # Use your existing create_game_tokens function\n",
    "            home_tokens, away_tokens = create_game_tokens(\n",
    "                game_id, season, home_team_id, away_team_id, game_row, player_id_mapping\n",
    "            )\n",
    "\n",
    "            # Target extraction\n",
    "            target = torch.tensor([game_row[\"home_team_score\"], game_row[\"visitor_team_score\"]], dtype=torch.float32)\n",
    "\n",
    "            return home_tokens, away_tokens, target\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Skipping game {game_id}: {e}\")\n",
    "            return None  # Returning None will be handled in the DataLoader collate function\n",
    "\n",
    "\n",
    "# Custom collate function to handle None\n",
    "def custom_collate_fn(batch):\n",
    "    # Filter out None values\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None, None, None\n",
    "    return default_collate(batch)  # Use PyTorch's default collate for valid data\n",
    "\n",
    "\n",
    "# Load games and player mapping\n",
    "games_df = pd.read_csv(\"expanded_games_2003_2023.csv\").set_index(\"game_id\")\n",
    "player_bio_df = pd.read_csv(\"playerBio.csv\").set_index(\"player_id\")\n",
    "player_id_mapping = player_bio_df[\"normalized_id\"].to_dict()\n",
    "\n",
    "# Initialize dataset and data loader\n",
    "dataset = NBA2003Dataset(games_df)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Model definition remains unchanged\n",
    "class LineupLab(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim=2):\n",
    "        super(LineupLab, self).__init__()\n",
    "        self.home_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.away_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.combined_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),  # Flatten the tokens and feature dimensions for each batch\n",
    "            nn.Linear(input_dim * 24, 128),  # Adjust for 24 tokens (12 home + 12 away)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, home_tokens, away_tokens):\n",
    "        # Apply home and away transformers\n",
    "        home_output = self.home_transformer(home_tokens)  # Shape: [batch_size, 12, input_dim]\n",
    "        away_output = self.away_transformer(away_tokens)  # Shape: [batch_size, 12, input_dim]\n",
    "        \n",
    "        # Concatenate outputs along the token dimension\n",
    "        combined_input = torch.cat((home_output, away_output), dim=1)  # Shape: [batch_size, 24, input_dim]\n",
    "        \n",
    "        # Pass through combined transformer\n",
    "        combined_output = self.combined_transformer(combined_input)  # Shape: [batch_size, 24, input_dim]\n",
    "        \n",
    "        # Flatten and pass through fully connected layers\n",
    "        scores = self.fc(combined_output)  # Shape: [batch_size, output_dim]\n",
    "        return scores\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "input_dim = 48\n",
    "hidden_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "model = LineupLab(input_dim, hidden_dim, num_heads, num_layers)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in data_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        home_tokens, away_tokens, target = batch\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(home_tokens, away_tokens)\n",
    "        loss = loss_fn(prediction, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 20685 games\n",
      "Validation data: 3649 games\n",
      "Testing data: 2613 games\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Epoch 1/10\n",
      "Train Loss: 364349.6297, Train Loss/Game/Team: 8.8131\n",
      "Train Percentage Loss: 0.73%\n",
      "Validation Loss: 37879.1936, Validation Loss/Game/Team: 5.1904\n",
      "Validation Percentage Loss: 0.58%\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Epoch 2/10\n",
      "Train Loss: 195883.7290, Train Loss/Game/Team: 4.7381\n",
      "Train Percentage Loss: 0.63%\n",
      "Validation Loss: 39538.6168, Validation Loss/Game/Team: 5.4177\n",
      "Validation Percentage Loss: 0.59%\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Epoch 3/10\n",
      "Train Loss: 185806.7196, Train Loss/Game/Team: 4.4944\n",
      "Train Percentage Loss: 0.61%\n",
      "Validation Loss: 39757.0586, Validation Loss/Game/Team: 5.4477\n",
      "Validation Percentage Loss: 0.61%\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Epoch 4/10\n",
      "Train Loss: 175771.4539, Train Loss/Game/Team: 4.2516\n",
      "Train Percentage Loss: 0.59%\n",
      "Validation Loss: 37302.8101, Validation Loss/Game/Team: 5.1114\n",
      "Validation Percentage Loss: 0.59%\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Epoch 5/10\n",
      "Train Loss: 167379.4398, Train Loss/Game/Team: 4.0487\n",
      "Train Percentage Loss: 0.58%\n",
      "Validation Loss: 38043.2773, Validation Loss/Game/Team: 5.2128\n",
      "Validation Percentage Loss: 0.58%\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Epoch 6/10\n",
      "Train Loss: 162531.5259, Train Loss/Game/Team: 3.9314\n",
      "Train Percentage Loss: 0.57%\n",
      "Validation Loss: 37512.3969, Validation Loss/Game/Team: 5.1401\n",
      "Validation Percentage Loss: 0.58%\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Epoch 7/10\n",
      "Train Loss: 157637.1561, Train Loss/Game/Team: 3.8130\n",
      "Train Percentage Loss: 0.56%\n",
      "Validation Loss: 42570.7042, Validation Loss/Game/Team: 5.8332\n",
      "Validation Percentage Loss: 0.60%\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Epoch 8/10\n",
      "Train Loss: 154815.8746, Train Loss/Game/Team: 3.7448\n",
      "Train Percentage Loss: 0.55%\n",
      "Validation Loss: 40049.8456, Validation Loss/Game/Team: 5.4878\n",
      "Validation Percentage Loss: 0.61%\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Epoch 9/10\n",
      "Train Loss: 150360.4128, Train Loss/Game/Team: 3.6370\n",
      "Train Percentage Loss: 0.54%\n",
      "Validation Loss: 38735.3896, Validation Loss/Game/Team: 5.3077\n",
      "Validation Percentage Loss: 0.58%\n",
      "Skipping game 34983: Static tensor not found: static_game_tensors_redo/season_2016/34983_home_static.pt\n",
      "Skipping game 46970: Static tensor not found: static_game_tensors_redo/season_2018/46970_home_static.pt\n",
      "Skipping game 19630: Static tensor not found: static_game_tensors_redo/season_2005/19630_home_static.pt\n",
      "Skipping game 17959: Static tensor not found: static_game_tensors_redo/season_2003/17959_home_static.pt\n",
      "Skipping game 31027: Static tensor not found: static_game_tensors_redo/season_2013/31027_home_static.pt\n",
      "Skipping game 22715: Static tensor not found: static_game_tensors_redo/season_2007/22715_home_static.pt\n",
      "Skipping game 49149: Static tensor not found: static_game_tensors_redo/season_2018/49149_home_static.pt\n",
      "Skipping game 49071: Static tensor not found: static_game_tensors_redo/season_2018/49071_home_static.pt\n",
      "Skipping game 21576: Static tensor not found: static_game_tensors_redo/season_2008/21576_home_static.pt\n",
      "Skipping game 48787: Static tensor not found: static_game_tensors_redo/season_2018/48787_home_static.pt\n",
      "Skipping game 19068: Static tensor not found: static_game_tensors_redo/season_2006/19068_home_static.pt\n",
      "Skipping game 25294: Static tensor not found: static_game_tensors_redo/season_2009/25294_home_static.pt\n",
      "Skipping game 29006: Static tensor not found: static_game_tensors_redo/season_2013/29006_home_static.pt\n",
      "Skipping game 49061: Static tensor not found: static_game_tensors_redo/season_2018/49061_home_static.pt\n",
      "Epoch 10/10\n",
      "Train Loss: 147845.9891, Train Loss/Game/Team: 3.5762\n",
      "Train Percentage Loss: 0.54%\n",
      "Validation Loss: 46626.4196, Validation Loss/Game/Team: 6.3889\n",
      "Validation Percentage Loss: 0.62%\n",
      "Cumulative Test Loss: 38153.0729\n",
      "Test Loss Per Game Per Team: 7.3006\n",
      "Test Percentage Loss: 0.65%\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"enable_nested_tensor is True, but self.use_nested_tensor is False because\"\n",
    "        \" encoder_layer.self_attn.batch_first was not True\"\n",
    "    ),\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\"You are using `torch.load` with `weights_only=False`.*\",\n",
    "    category=FutureWarning\n",
    ")\n",
    "\n",
    "STATIC_TENSOR_DIR = \"static_game_tensors_redo\"\n",
    "\n",
    "# Dataset class for all seasons\n",
    "class NBAFullDataset(Dataset):\n",
    "    def __init__(self, games_df):\n",
    "        self.games_df = games_df\n",
    "        self.game_ids = self.games_df.index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.game_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        game_id = self.game_ids[idx]\n",
    "\n",
    "        try:\n",
    "            # Extract the row as a Series\n",
    "            game_row = self.games_df.loc[game_id]\n",
    "            if isinstance(game_row, pd.DataFrame):  # Handle duplicate game_id scenario\n",
    "                game_row = game_row.iloc[0]  # Take the first occurrence\n",
    "\n",
    "            # Ensure all scalar values\n",
    "            season = int(game_row[\"season\"])\n",
    "            home_team_id = int(game_row[\"home_team_id\"])\n",
    "            away_team_id = int(game_row[\"visitor_team_id\"])\n",
    "\n",
    "            # Use the existing create_game_tokens function\n",
    "            home_tokens, away_tokens = create_game_tokens(\n",
    "                game_id, season, home_team_id, away_team_id, game_row, player_id_mapping\n",
    "            )\n",
    "\n",
    "            # Target extraction\n",
    "            target = torch.tensor([game_row[\"home_team_score\"], game_row[\"visitor_team_score\"]], dtype=torch.float32)\n",
    "\n",
    "            return home_tokens, away_tokens, target\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Skipping game {game_id}: {e}\")\n",
    "            return None  # Returning None will be handled in the DataLoader collate function\n",
    "\n",
    "\n",
    "# Custom collate function to handle None\n",
    "def custom_collate_fn(batch):\n",
    "    # Filter out None values\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None, None, None\n",
    "    return default_collate(batch)  # Use PyTorch's default collate for valid data\n",
    "\n",
    "\n",
    "# Load games and player mapping\n",
    "games_df = pd.read_csv(\"expanded_games_2003_2023.csv\").set_index(\"game_id\")\n",
    "player_bio_df = pd.read_csv(\"playerBio.csv\").set_index(\"player_id\")\n",
    "player_id_mapping = player_bio_df[\"normalized_id\"].to_dict()\n",
    "\n",
    "# Split the data by year\n",
    "train_df = games_df[games_df[\"season\"].isin(range(2003, 2019))]\n",
    "val_df = games_df[games_df[\"season\"].isin(range(2019, 2022))]\n",
    "test_df = games_df[games_df[\"season\"].isin(range(2022, 2024))]\n",
    "\n",
    "# Print sizes to verify splits\n",
    "print(f\"Training data: {len(train_df)} games\")\n",
    "print(f\"Validation data: {len(val_df)} games\")\n",
    "print(f\"Testing data: {len(test_df)} games\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NBAFullDataset(train_df)\n",
    "val_dataset = NBAFullDataset(val_df)\n",
    "test_dataset = NBAFullDataset(test_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Model definition remains unchanged\n",
    "class LineupLab(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim=2):\n",
    "        super(LineupLab, self).__init__()\n",
    "        self.home_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.away_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.combined_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),  # Flatten the tokens and feature dimensions for each batch\n",
    "            nn.Linear(input_dim * 24, 128),  # Adjust for 24 tokens (12 home + 12 away)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, home_tokens, away_tokens):\n",
    "        # Apply home and away transformers\n",
    "        home_output = self.home_transformer(home_tokens)  # Shape: [batch_size, 12, input_dim]\n",
    "        away_output = self.away_transformer(away_tokens)  # Shape: [batch_size, 12, input_dim]\n",
    "\n",
    "        # Concatenate outputs along the token dimension\n",
    "        combined_input = torch.cat((home_output, away_output), dim=1)  # Shape: [batch_size, 24, input_dim]\n",
    "\n",
    "        # Pass through combined transformer\n",
    "        combined_output = self.combined_transformer(combined_input)  # Shape: [batch_size, 24, input_dim]\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        scores = self.fc(combined_output)  # Shape: [batch_size, output_dim]\n",
    "        return scores\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = 48\n",
    "hidden_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "model = LineupLab(input_dim, hidden_dim, num_heads, num_layers)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Percentage loss function (MAPE)\n",
    "def percentage_loss(pred, target):\n",
    "    return torch.mean(torch.abs((pred - target) / target)) * 100\n",
    "\n",
    "# Training and validation loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_percentage_loss = 0\n",
    "    train_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "\n",
    "        # Unpack batch\n",
    "        home_tokens, away_tokens, target = batch\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(home_tokens, away_tokens)\n",
    "\n",
    "        # Compute losses\n",
    "        mse_loss = loss_fn(prediction, target)\n",
    "        perc_loss = percentage_loss(prediction, target)\n",
    "\n",
    "        # Backward pass\n",
    "        mse_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += mse_loss.item()\n",
    "        train_percentage_loss += perc_loss.item()\n",
    "        train_samples += target.size(0)  # Add the number of games in the batch\n",
    "\n",
    "    train_loss_per_game_team = train_loss / (2 * train_samples)  # Divide by 2 for home and away\n",
    "    train_percentage_loss_avg = train_percentage_loss / train_samples\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_percentage_loss = 0\n",
    "    val_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if batch is None:\n",
    "                continue\n",
    "\n",
    "            # Unpack batch\n",
    "            home_tokens, away_tokens, target = batch\n",
    "\n",
    "            # Forward pass\n",
    "            prediction = model(home_tokens, away_tokens)\n",
    "\n",
    "            # Compute losses\n",
    "            mse_loss = loss_fn(prediction, target)\n",
    "            perc_loss = percentage_loss(prediction, target)\n",
    "\n",
    "            val_loss += mse_loss.item()\n",
    "            val_percentage_loss += perc_loss.item()\n",
    "            val_samples += target.size(0)  # Add the number of games in the batch\n",
    "\n",
    "    val_loss_per_game_team = val_loss / (2 * val_samples)  # Divide by 2 for home and away\n",
    "    val_percentage_loss_avg = val_percentage_loss / val_samples\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Loss/Game/Team: {train_loss_per_game_team:.4f}\")\n",
    "    print(f\"Train Percentage Loss: {train_percentage_loss_avg:.2f}%\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Loss/Game/Team: {val_loss_per_game_team:.4f}\")\n",
    "    print(f\"Validation Percentage Loss: {val_percentage_loss_avg:.2f}%\")\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_percentage_loss = 0\n",
    "test_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "\n",
    "        home_tokens, away_tokens, target = batch\n",
    "\n",
    "        # Forward pass\n",
    "        prediction = model(home_tokens, away_tokens)\n",
    "\n",
    "        # Compute losses\n",
    "        mse_loss = loss_fn(prediction, target)\n",
    "        perc_loss = percentage_loss(prediction, target)\n",
    "\n",
    "        test_loss += mse_loss.item()\n",
    "        test_percentage_loss += perc_loss.item()\n",
    "        test_samples += target.size(0)\n",
    "\n",
    "test_loss_per_game_team = test_loss / (2 * test_samples)\n",
    "test_percentage_loss_avg = test_percentage_loss / test_samples\n",
    "\n",
    "print(f\"Cumulative Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Loss Per Game Per Team: {test_loss_per_game_team:.4f}\")\n",
    "print(f\"Test Percentage Loss: {test_percentage_loss_avg:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic embeddings saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Directory to save embeddings\n",
    "embedding_save_dir = \"saved_embeddings\"\n",
    "os.makedirs(embedding_save_dir, exist_ok=True)\n",
    "\n",
    "# Save each embedding separately\n",
    "torch.save(player_embedding.state_dict(), os.path.join(embedding_save_dir, \"player_embedding.pt\"))\n",
    "torch.save(position_embedding.state_dict(), os.path.join(embedding_save_dir, \"position_embedding.pt\"))\n",
    "torch.save(team_embedding.state_dict(), os.path.join(embedding_save_dir, \"team_embedding.pt\"))\n",
    "torch.save(season_embedding.state_dict(), os.path.join(embedding_save_dir, \"season_embedding.pt\"))\n",
    "\n",
    "print(\"Dynamic embeddings saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic embeddings have been reset to their initial state.\n"
     ]
    }
   ],
   "source": [
    "# Reset dynamic embeddings\n",
    "def reset_embeddings():\n",
    "    global player_embedding, position_embedding, team_embedding, season_embedding\n",
    "\n",
    "    # Reinitialize embeddings with the same dimensions and ranges\n",
    "    player_embedding = nn.Embedding(max_normalized_player_id + 1, E_player)\n",
    "    position_embedding = nn.Embedding(max_position_id + 1, E_position)\n",
    "    team_embedding = nn.Embedding(max_team_id + 1, E_team)\n",
    "    season_embedding = nn.Embedding(max_season_id + 1, E_season)\n",
    "\n",
    "    print(\"Dynamic embeddings have been reset to their initial state.\")\n",
    "\n",
    "# Example usage\n",
    "reset_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic embeddings loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Directory to load embeddings\n",
    "embedding_save_dir = \"saved_embeddings\"\n",
    "\n",
    "# Reload embeddings\n",
    "player_embedding = nn.Embedding(max_normalized_player_id + 1, E_player)\n",
    "player_embedding.load_state_dict(torch.load(os.path.join(embedding_save_dir, \"player_embedding.pt\")))\n",
    "\n",
    "position_embedding = nn.Embedding(max_position_id + 1, E_position)\n",
    "position_embedding.load_state_dict(torch.load(os.path.join(embedding_save_dir, \"position_embedding.pt\")))\n",
    "\n",
    "team_embedding = nn.Embedding(max_team_id + 1, E_team)\n",
    "team_embedding.load_state_dict(torch.load(os.path.join(embedding_save_dir, \"team_embedding.pt\")))\n",
    "\n",
    "season_embedding = nn.Embedding(max_season_id + 1, E_season)\n",
    "season_embedding.load_state_dict(torch.load(os.path.join(embedding_save_dir, \"season_embedding.pt\")))\n",
    "\n",
    "print(\"Dynamic embeddings loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 20685 games\n",
      "Validation data: 3649 games\n",
      "Testing data: 2613 games\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "NaN detected in player token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1537/733664663.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1537/733664663.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# Create tokens for both teams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             home_tokens, away_tokens = create_game_tokens(\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mgame_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhome_team_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maway_team_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             )\n",
      "\u001b[0;32m/tmp/ipykernel_1537/102593236.py\u001b[0m in \u001b[0;36mcreate_game_tokens\u001b[0;34m(game_id, season, home_team_id, away_team_id, games_df)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"player_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         player_token = create_player_token(\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mplayer_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"player_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mposition_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"position_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1537/102593236.py\u001b[0m in \u001b[0;36mcreate_player_token\u001b[0;34m(player_id, position_id, team_id_for, team_id_against, season_id, static_tensor)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Concatenate dynamic and static features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer_id_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteam_for_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteam_against_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NaN detected in player token\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: NaN detected in player token"
     ]
    }
   ],
   "source": [
    "# Full training cycle for LineupLab with training, validation, and testing.\n",
    "# Define year ranges for splits\n",
    "train_years = range(2003, 2019)  # Training: 2003–2018\n",
    "val_years = range(2019, 2022)    # Validation: 2019–2021\n",
    "test_years = range(2022, 2024)   # Testing: 2022–2023\n",
    "\n",
    "# Split the data by year\n",
    "games_df = pd.read_csv(\"expanded_games_2003_2023.csv\").set_index(\"game_id\")\n",
    "train_df = games_df[games_df[\"season\"].isin(train_years)]\n",
    "val_df = games_df[games_df[\"season\"].isin(val_years)]\n",
    "test_df = games_df[games_df[\"season\"].isin(test_years)]\n",
    "\n",
    "# Print sizes to verify splits\n",
    "print(f\"Training data: {len(train_df)} games\")\n",
    "print(f\"Validation data: {len(val_df)} games\")\n",
    "print(f\"Testing data: {len(test_df)} games\")\n",
    "\n",
    "# Dataset class for all seasons with data validation\n",
    "class NBAFullDataset(Dataset):\n",
    "    def __init__(self, games_df):\n",
    "        # Clean dataset: remove rows with missing or invalid data\n",
    "        self.games_df = games_df.dropna()\n",
    "        self.game_ids = self.games_df.index.tolist()\n",
    "        self.position_mapping = {\"C\": 0, \"F\": 1, \"G\": 2, None: 3}  # Map positions to integers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.game_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        game_id = self.game_ids[idx]\n",
    "        try:\n",
    "            # Extract the row as a Series\n",
    "            game_row = self.games_df.loc[game_id]\n",
    "            if isinstance(game_row, pd.DataFrame):  # Handle duplicate game_id scenario\n",
    "                game_row = game_row.iloc[0]  # Take the first occurrence\n",
    "\n",
    "            # Ensure all scalar values\n",
    "            season = int(game_row[\"season\"])\n",
    "            home_team_id = int(game_row[\"home_team_id\"])\n",
    "            away_team_id = int(game_row[\"visitor_team_id\"])\n",
    "\n",
    "            # Load static tensors\n",
    "            home_static_tensor_path = f\"static_game_tensors_redo/season_{season}/{game_id}_home_static.pt\"\n",
    "            away_static_tensor_path = f\"static_game_tensors_redo/season_{season}/{game_id}_away_static.pt\"\n",
    "\n",
    "            if not os.path.exists(home_static_tensor_path) or not os.path.exists(away_static_tensor_path):\n",
    "                raise FileNotFoundError(f\"Static tensor not found for game {game_id}\")\n",
    "\n",
    "            home_static_tensor = torch.load(home_static_tensor_path)\n",
    "            away_static_tensor = torch.load(away_static_tensor_path)\n",
    "\n",
    "            # Extract player data dynamically from the dataframe\n",
    "            home_players = [\n",
    "                {\"player_id\": int(game_row[f\"home_player_{i}_id\"]) if not pd.isna(game_row[f\"home_player_{i}_id\"]) else None,\n",
    "                 \"position_id\": self.position_mapping.get(game_row[f\"home_player_{i}_position\"], 3)}\n",
    "                for i in range(1, 13)\n",
    "            ]\n",
    "            away_players = [\n",
    "                {\"player_id\": int(game_row[f\"away_player_{i}_id\"]) if not pd.isna(game_row[f\"away_player_{i}_id\"]) else None,\n",
    "                 \"position_id\": self.position_mapping.get(game_row[f\"away_player_{i}_position\"], 3)}\n",
    "                for i in range(1, 13)\n",
    "            ]\n",
    "\n",
    "            # Create tokens for both teams\n",
    "            home_tokens, away_tokens = create_game_tokens(\n",
    "                game_id, season, home_team_id, away_team_id, game_row\n",
    "            )\n",
    "\n",
    "            # Target extraction\n",
    "            target = torch.tensor([game_row[\"home_team_score\"], game_row[\"visitor_team_score\"]], dtype=torch.float32)\n",
    "\n",
    "            # Sanity checks\n",
    "            assert not torch.isnan(home_tokens).any(), f\"NaN in home tokens for game {game_id}\"\n",
    "            assert not torch.isnan(away_tokens).any(), f\"NaN in away tokens for game {game_id}\"\n",
    "            assert not torch.isnan(target).any(), f\"NaN in target for game {game_id}\"\n",
    "\n",
    "            return home_tokens, away_tokens, target\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Skipping game {game_id}: {e}\")\n",
    "            return None  # Return None for missing data\n",
    "\n",
    "# Custom collate function to handle None\n",
    "def custom_collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]  # Filter out None values\n",
    "    if len(batch) == 0:\n",
    "        return None, None, None\n",
    "    return default_collate(batch)  # Use PyTorch's default collate for valid data\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NBAFullDataset(train_df)\n",
    "val_dataset = NBAFullDataset(val_df)\n",
    "test_dataset = NBAFullDataset(test_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Model definition\n",
    "class LineupLab(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim=2):\n",
    "        super(LineupLab, self).__init__()\n",
    "        self.home_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.away_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.combined_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),  # Flatten the tokens and feature dimensions for each batch\n",
    "            nn.Linear(input_dim * 24, 128),  # Adjust for 24 tokens (12 home + 12 away)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, home_tokens, away_tokens):\n",
    "        # Apply home and away transformers\n",
    "        home_output = self.home_transformer(home_tokens)  # Shape: [batch_size, 12, input_dim]\n",
    "        away_output = self.away_transformer(away_tokens)  # Shape: [batch_size, 12, input_dim]\n",
    "\n",
    "        # Concatenate outputs along the token dimension\n",
    "        combined_input = torch.cat((home_output, away_output), dim=1)  # Shape: [batch_size, 24, input_dim]\n",
    "\n",
    "        # Pass through combined transformer\n",
    "        combined_output = self.combined_transformer(combined_input)  # Shape: [batch_size, 24, input_dim]\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        scores = self.fc(combined_output)  # Shape: [batch_size, output_dim]\n",
    "        return scores\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = 48\n",
    "hidden_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "model = LineupLab(input_dim, hidden_dim, num_heads, num_layers)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training loop with debugging\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "\n",
    "        # Unpack batch\n",
    "        home_tokens, away_tokens, target = batch\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(home_tokens, away_tokens)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(prediction, target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        home_tokens, away_tokens, target = batch\n",
    "        prediction = model(home_tokens, away_tokens)\n",
    "        loss = loss_fn(prediction, target)\n",
    "        test_loss += loss.item()\n",
    "print(f\"Cumulative Test Loss: {test_loss:.4f}\")        \n",
    "print(f\"Test Loss Per Game Per Team: {test_loss / (2 * len(test_loader.dataset)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training cycle for LineupLab with training, validation, and testing.\n",
    "# Define year ranges for splits\n",
    "train_years = range(2003, 2019)  # Training: 2003–2018\n",
    "val_years = range(2019, 2022)    # Validation: 2019–2021\n",
    "test_years = range(2022, 2024)   # Testing: 2022–2023\n",
    "\n",
    "# Split the data by year\n",
    "games_df = pd.read_csv(\"expanded_games_2003_2023.csv\").set_index(\"game_id\")\n",
    "train_df = games_df[games_df[\"season\"].isin(train_years)]\n",
    "val_df = games_df[games_df[\"season\"].isin(val_years)]\n",
    "test_df = games_df[games_df[\"season\"].isin(test_years)]\n",
    "\n",
    "# Print sizes to verify splits\n",
    "print(f\"Training data: {len(train_df)} games\")\n",
    "print(f\"Validation data: {len(val_df)} games\")\n",
    "print(f\"Testing data: {len(test_df)} games\")\n",
    "\n",
    "# Dataset class for all seasons\n",
    "class NBAFullDataset(Dataset):\n",
    "    def __init__(self, games_df, position_mapping):\n",
    "        self.games_df = games_df\n",
    "        self.position_mapping = position_mapping\n",
    "        self.game_ids = self.games_df.index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.game_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        game_id = self.game_ids[idx]\n",
    "        try:\n",
    "            game_row = self.games_df.loc[game_id]\n",
    "            if isinstance(game_row, pd.DataFrame):  # Handle duplicate game_id scenario\n",
    "                game_row = game_row.iloc[0]\n",
    "\n",
    "            season = int(game_row[\"season\"])\n",
    "            home_team_id = int(game_row[\"home_team_id\"])\n",
    "            away_team_id = int(game_row[\"visitor_team_id\"])\n",
    "\n",
    "            # Load static tensors\n",
    "            home_static_tensor_path = f\"static_game_tensors/season_{season}/{game_id}_home_static.pt\"\n",
    "            away_static_tensor_path = f\"static_game_tensors/season_{season}/{game_id}_away_static.pt\"\n",
    "            if not os.path.exists(home_static_tensor_path) or not os.path.exists(away_static_tensor_path):\n",
    "                raise FileNotFoundError(f\"Static tensor not found for game {game_id}\")\n",
    "\n",
    "            home_static_tensor = torch.load(home_static_tensor_path)\n",
    "            away_static_tensor = torch.load(away_static_tensor_path)\n",
    "\n",
    "            # Extract player data\n",
    "            home_players = [\n",
    "                {\"player_id\": int(game_row[f\"home_player_{i}_id\"]) if not pd.isna(game_row[f\"home_player_{i}_id\"]) else None,\n",
    "                 \"position_id\": self.position_mapping.get(game_row[f\"home_player_{i}_position\"], 3)}\n",
    "                for i in range(1, 13)\n",
    "            ]\n",
    "            away_players = [\n",
    "                {\"player_id\": int(game_row[f\"away_player_{i}_id\"]) if not pd.isna(game_row[f\"away_player_{i}_id\"]) else None,\n",
    "                 \"position_id\": self.position_mapping.get(game_row[f\"away_player_{i}_position\"], 3)}\n",
    "                for i in range(1, 13)\n",
    "            ]\n",
    "\n",
    "            return {\n",
    "                \"home_static_tensor\": home_static_tensor,\n",
    "                \"away_static_tensor\": away_static_tensor,\n",
    "                \"home_players\": home_players,\n",
    "                \"away_players\": away_players,\n",
    "                \"season_id\": season - 2003,  # Normalize season\n",
    "                \"home_team_id\": home_team_id,\n",
    "                \"away_team_id\": away_team_id,\n",
    "                \"target\": torch.tensor([game_row[\"home_team_score\"], game_row[\"visitor_team_score\"]], dtype=torch.float32)\n",
    "            }\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Skipping game {game_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# Custom collate function\n",
    "def custom_collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    return default_collate(batch)\n",
    "\n",
    "# Embedding parameters\n",
    "max_player_id = 2500\n",
    "max_position_id = 3\n",
    "max_team_id = 32\n",
    "max_season_id = 22\n",
    "\n",
    "# Model definition\n",
    "class LineupLab(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, max_player_id, max_position_id, max_team_id, max_season_id, output_dim=2):\n",
    "        super(LineupLab, self).__init__()\n",
    "        # Embedding layers\n",
    "        self.player_embedding = nn.Embedding(max_player_id + 1, 18)\n",
    "        self.position_embedding = nn.Embedding(max_position_id + 1, 4)\n",
    "        self.team_embedding = nn.Embedding(max_team_id + 1, 8)\n",
    "        self.season_embedding = nn.Embedding(max_season_id + 1, 4)\n",
    "\n",
    "        # Transformers\n",
    "        self.home_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.away_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.combined_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(input_dim * 24, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Generate tokens for both teams\n",
    "        def generate_team_tokens(players, team_id_for, team_id_against, static_tensor, season_id):\n",
    "            tokens = []\n",
    "            for i, player in enumerate(players):\n",
    "                if player[\"player_id\"] is None:\n",
    "                    continue\n",
    "                player_token = torch.cat([\n",
    "                    self.player_embedding(torch.tensor(player[\"player_id\"])),\n",
    "                    self.position_embedding(torch.tensor(player[\"position_id\"])),\n",
    "                    self.team_embedding(torch.tensor(team_id_for)),\n",
    "                    self.team_embedding(torch.tensor(team_id_against)),\n",
    "                    self.season_embedding(torch.tensor(season_id)),\n",
    "                    static_tensor[i]\n",
    "                ])\n",
    "                tokens.append(player_token)\n",
    "            return torch.stack(tokens)\n",
    "\n",
    "        home_tokens = generate_team_tokens(\n",
    "            data[\"home_players\"], data[\"home_team_id\"], data[\"away_team_id\"], data[\"home_static_tensor\"], data[\"season_id\"]\n",
    "        )\n",
    "        away_tokens = generate_team_tokens(\n",
    "            data[\"away_players\"], data[\"away_team_id\"], data[\"home_team_id\"], data[\"away_static_tensor\"], data[\"season_id\"]\n",
    "        )\n",
    "\n",
    "        # Apply transformers\n",
    "        home_output = self.home_transformer(home_tokens)\n",
    "        away_output = self.away_transformer(away_tokens)\n",
    "        combined_input = torch.cat((home_output, away_output), dim=1)\n",
    "        combined_output = self.combined_transformer(combined_input)\n",
    "\n",
    "        # Fully connected layers\n",
    "        return self.fc(combined_output)\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "position_mapping = {\"C\": 0, \"F\": 1, \"G\": 2, None: 3}\n",
    "train_dataset = NBAFullDataset(train_df, position_mapping)\n",
    "val_dataset = NBAFullDataset(val_df, position_mapping)\n",
    "test_dataset = NBAFullDataset(test_df, position_mapping)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = LineupLab(\n",
    "    input_dim=48,\n",
    "    hidden_dim=128,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    max_player_id=max_player_id,\n",
    "    max_position_id=max_position_id,\n",
    "    max_team_id=max_team_id,\n",
    "    max_season_id=max_season_id\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training and validation loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(batch)\n",
    "        loss = loss_fn(prediction, batch[\"target\"])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if batch is None:\n",
    "                continue\n",
    "            prediction = model(batch)\n",
    "            loss = loss_fn(prediction, batch[\"target\"])\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model on a single game\n",
    "def test_model_on_game(game_id, season, model, games_df, static_tensor_dir=\"static_game_tensors\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    position_mapping = {\"C\": 0, \"F\": 1, \"G\": 2, None: 3}  # Map positions to integers\n",
    "\n",
    "    try:\n",
    "        # Extract game row from DataFrame\n",
    "        game_row = games_df.loc[game_id]\n",
    "        if isinstance(game_row, pd.DataFrame):  # Handle duplicate game_id scenario\n",
    "            game_row = game_row.iloc[0]  # Take the first occurrence\n",
    "\n",
    "        # Load static tensors\n",
    "        home_static_tensor = load_static_tensor(game_id, \"home\", season)\n",
    "        away_static_tensor = load_static_tensor(game_id, \"away\", season)\n",
    "\n",
    "        # Extract player data dynamically\n",
    "        home_players = [\n",
    "            {\"player_id\": int(game_row[f\"home_player_{i}_id\"]) if not pd.isna(game_row[f\"home_player_{i}_id\"]) else None,\n",
    "             \"position_id\": position_mapping.get(game_row[f\"home_player_{i}_position\"], 3)}\n",
    "            for i in range(1, 13)\n",
    "        ]\n",
    "        away_players = [\n",
    "            {\"player_id\": int(game_row[f\"away_player_{i}_id\"]) if not pd.isna(game_row[f\"away_player_{i}_id\"]) else None,\n",
    "             \"position_id\": position_mapping.get(game_row[f\"away_player_{i}_position\"], 3)}\n",
    "            for i in range(1, 13)\n",
    "        ]\n",
    "\n",
    "        # Create tokens for both teams\n",
    "        home_tokens, away_tokens = create_game_tokens(\n",
    "            game_id, season, int(game_row[\"home_team_id\"]), int(game_row[\"visitor_team_id\"]), game_row\n",
    "        )\n",
    "\n",
    "        # Check if home_tokens and away_tokens are already tensors, otherwise convert them\n",
    "        if not isinstance(home_tokens, torch.Tensor):\n",
    "            home_tokens_tensor = torch.tensor(home_tokens).unsqueeze(0)  # Shape: [1, 12, input_dim]\n",
    "        else:\n",
    "            home_tokens_tensor = home_tokens.unsqueeze(0)\n",
    "\n",
    "        if not isinstance(away_tokens, torch.Tensor):\n",
    "            away_tokens_tensor = torch.tensor(away_tokens).unsqueeze(0)  # Shape: [1, 12, input_dim]\n",
    "        else:\n",
    "            away_tokens_tensor = away_tokens.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "        # Perform prediction\n",
    "        with torch.no_grad():\n",
    "            predicted_scores = model(home_tokens_tensor, away_tokens_tensor)\n",
    "\n",
    "        # Extract ground truth scores\n",
    "        actual_scores = torch.tensor(\n",
    "            [game_row[\"home_team_score\"], game_row[\"visitor_team_score\"]], dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Output results\n",
    "        print(f\"Game ID: {game_id}\")\n",
    "        print(f\"Season: {season}\")\n",
    "        print(f\"Predicted Scores: Home: {predicted_scores[0, 0].item():.2f}, Away: {predicted_scores[0, 1].item():.2f}\")\n",
    "        print(f\"Actual Scores: Home: {actual_scores[0].item()}, Away: {actual_scores[1].item()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing game {game_id}: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "games_df = pd.read_csv(\"expanded_games_2003_2023.csv\").set_index(\"game_id\")\n",
    "game_id_to_test = 15882412  # Replace with the actual game ID from another season\n",
    "season_to_test = 2023    # Replace with the actual season for the game ID\n",
    "\n",
    "test_model_on_game(game_id_to_test, season_to_test, model, games_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **III. Hyperparameter Tuning**\n",
    "\n",
    "### Overview\n",
    "This section explores the impact of various hyperparameters on the model's performance. By systematically adjusting key parameters, we aim to optimize the transformer network for better predictions.\n",
    "\n",
    "### Goals\n",
    "1. **Experimentation**:\n",
    "   - Test different values for hyperparameters such as:\n",
    "     - Learning rate.\n",
    "     - Number of epochs.\n",
    "     - Optimizer (e.g., Adam, SGD).\n",
    "     - Batch size.\n",
    "     - Number of transformer layers and attention heads.\n",
    "2. **Performance Evaluation**:\n",
    "   - Assess the impact of each hyperparameter on model accuracy, loss, and F1-score.\n",
    "   - Document observations to identify the most effective configurations.\n",
    "\n",
    "### Implementation Steps\n",
    "1. **Baseline Configuration**:\n",
    "   - Train the model with default or commonly used hyperparameter values.\n",
    "   - Record baseline performance metrics.\n",
    "2. **Iterative Testing**:\n",
    "   - Adjust one hyperparameter at a time while keeping others constant.\n",
    "   - Monitor changes in performance and identify trends.\n",
    "3. **Optimal Configuration**:\n",
    "   - Combine the best-performing hyperparameters into a final configuration for training the model.\n",
    "\n",
    "This section will detail the experiments conducted and the resulting insights into hyperparameter optimization for the transformer network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IV. Evaluation and Analysis**\n",
    "\n",
    "### Overview\n",
    "In this section, we evaluate the performance of the transformer-based model using two primary loss metrics and other relevant performance indicators. The focus will be on understanding the model's strengths, limitations, and areas for improvement.\n",
    "\n",
    "### Metrics\n",
    "1. **Score Prediction Accuracy**:\n",
    "   - Measure the actual distance between predicted scores and the true game scores (e.g., Mean Squared Error or Mean Absolute Error).\n",
    "   - Assess how well the model captures the scoring trends in games.\n",
    "2. **Winning Outcome Prediction**:\n",
    "   - Evaluate the model's ability to correctly predict the winning team (e.g., Accuracy, F1-score).\n",
    "   - Analyze classification performance using confusion matrices.\n",
    "\n",
    "### Goals\n",
    "1. **Performance Metrics**:\n",
    "   - Quantify how accurately the model predicts game outcomes and scores.\n",
    "   - Identify patterns or biases in the model’s predictions.\n",
    "2. **Visual Representations**:\n",
    "   - Plot training and validation loss over epochs.\n",
    "   - Generate confusion matrices for winning outcome predictions.\n",
    "   - Visualize score prediction distributions.\n",
    "3. **Strengths and Limitations**:\n",
    "   - Discuss areas where the model performs well and where it struggles.\n",
    "   - Identify real-world scenarios where the model could be applied effectively.\n",
    "4. **Future Improvements**:\n",
    "   - Suggest ways to enhance the model, such as adjusting hyperparameters, adding new features, or increasing dataset size.\n",
    "\n",
    "This section will summarize the model's overall performance, supported by quantitative metrics and visualizations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
